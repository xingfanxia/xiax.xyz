---
title: "AI的最后一公里"
date: "2026-02-22"
summary: "一个周末，一个非工程师朋友，一台电脑——教他用AI Agent的过程让我看到了Agent革命真正的瓶颈：不是技术，不是成本，而是认知。"
tags: ["AI", "Agents"]
series: "AI智能体随想"
part: 5
type: "Post"
status: "Published"
---

## 一个周末，一个朋友，一台电脑

一个老朋友从北京来西雅图出差。除了叙旧，他有一个明确的目的：想学怎么用 AI Agent 提高效率。

他是我大学时期最好的朋友之一，做金融的——看各种 deal、写投资研报。大学时选过几节 CS 入门课，但那已经是八年前的事了，早就还给老师了。他很聪明，学东西快，而且——最关键的——他有强烈的动机。我平时经常和他分享我用 AI Agent 的各种 use case，他亲眼看到这些东西的潜力，知道自己不能再等了。

于是我们花了一个周末做了一件事：我手把手教他用 Claude Code。

我们从零开始：在 GCP 上部署了他自己的 OpenClaw 实例，接入了飞书，配置了 tunnel，然后用 Claude Code 做了一系列他真正需要的事情——财务分析、数据整理、甚至给他的业务场景搭了一个定制化的小工具。

这个周末让我看到了三件事，每一件都比我之前的理论思考更直接、更真实。

## 最后一公里

[上一篇](/when-software-becomes-disposable-zh)我写到 Agent Marketplace 的"对话式入口"——用户不该在货架上挑选 Agent，而是直接说出需求让平台匹配。听起来很美。

但现实是：在我朋友能"对话"之前，他得先跨过一道巨大的门槛。

GCP 账号注册、gcloud CLI 安装、服务器配置、OpenClaw 部署、飞书集成、tunnel 转发……每一步对我来说都是几分钟的事，但对他来说都是"这是什么？为什么要这样？"的连环问号。不是因为他笨——是因为这些东西对非技术人员来说根本不在认知范围内。

有趣的是，一旦环境搭好，Claude Code 几乎可以处理后面的所有事情。它帮他写脚本、读文档、调试错误、部署服务。问题不在 Agent 本身——Agent 已经足够强了。**问题在于从"我想要一个 Agent"到"我有一个能用的 Agent"之间的那段距离。**

这就是 Agent 革命的"最后一公里"问题。

物流行业有一个经典的概念：最后一公里是整个配送链中成本最高、效率最低的环节。仓库到城市很快，城市到小区很快，但从小区门口到你家门口——这最后几百米，吃掉了整个链条中不成比例的资源。

Agent 领域的情况完全一样。大模型的能力已经到了。Claude Code 作为通用 Agent 已经足够强大。Skills 生态在形成。但**从普通用户到能用上这些东西之间的那段基础设施，几乎是空白的。**

每个人都在讨论 Agent 能做什么。很少有人在解决普通人怎么用上 Agent。

其实有一些产品在一定程度上解决了入口问题。就拿我自己的例子——我用 OpenClaw 在 GCP 上给盘盘猫搭了一个全自动的 AI 工程师，接入了飞书群。团队成员不需要向我提交 bug 报告或 feature request，他们直接在飞书群里和 Agent 对话。Agent 会自动验证、分类问题，创建 GitHub Issue，生成任务追踪；简单的 bug 直接提交修复 PR；复杂的结构性改动和新功能需求，Agent 会在 GitHub Issue 里生成一份详细的报告——包含上下文、分析和建议。这极大地解放了我：我不再需要一个个跟团队成员收集信息，我只需要思考和做决定。

对团队成员来说，使用 Agent 就像在飞书里找一个同事聊天一样简单。入口问题确实被解决了。

但搭建这个体验的人是我——一个每天在 Claude Code 里工作的工程师。**普通用户没有能力、没有意愿、也没有认知去完成这个搭建过程。** 他们甚至不知道这种体验是可能的。

所以"最后一公里"的本质不是"Agent 不好用"——而是"必须有人替你铺好那段路"。目前，这个铺路人只能是技术人员。而绝大多数人身边，没有一个愿意花时间帮他们铺路的技术人员。

Anthropic 也看到了这个问题。Boris Cherny——Claude Code 的创造者——在最近的访谈里提到：在 Anthropic 内部，设计师、数据科学家、甚至财务团队都在"跳过重重障碍"去安装终端里的 Claude Code。非工程师的员工自己搞定了 Node.js 安装和终端命令——只为能用上 Agent 级别的能力。外部用户也一样：有人用它监控番茄苗的生长，有人用它从损坏的硬盘里恢复婚礼照片，有人用它做财务分析。需求是明确无误的——但门槛也是荒谬的。一个终端命令行工具，不应该是"想用 AI 交停车罚款"的人的入口。

于是 Anthropic 造了 Cowork：把 Claude Code 包进一个易用的桌面界面，运行在虚拟机里，加了删除保护和权限提示。四个工程师用十天做出来，代码完全由 Claude Code 自己写的。Cowork 是第一个认真尝试在规模上铺设"最后一公里"的产品。它拥有 Claude Code 完整的 Agent 能力，但去掉了终端门槛。Anthropic 的销售团队已经开始从 Claude Code 迁移到 Cowork——"因为更容易上手，而且有虚拟机所以更安全一点，"Boris 说。

这并没有解决全部问题——用户仍然需要学会怎么下好指令、怎么用目标而不是步骤来思考。但它移除了最残酷的那道门槛：你不再需要是个工程师才能开始。

## 认知鸿沟

第二个发现比第一个更深。

我朋友不是不知道 AI 存在——他用过 ChatGPT，用过豆包，用过各种免费的聊天机器人。他对 AI 的认知是："一个比搜索引擎聪明一点的问答工具。"

这大概是 99.99% 的人对 AI 的理解。

但我朋友不一样。因为我平时和他分享过很多 case，他是带着 expectation 来的——他知道这东西"应该很厉害"。但知道和亲眼看到是两回事。

当 Claude Code 帮他做财务分析时——不是"回答关于财务的问题"，而是真正读取他的数据、建模、生成分析报告、然后根据他的反馈迭代——他的反应不是"嗯，和你说的一样"。他的反应是**真正的震撼**。那种"我知道它能做，但亲眼看到它在我的数据上做，感觉完全不一样"的震撼。

然后我们搞了一个更有趣的项目：用 Claude Code 从零做了一个用声音音调高低来控制的 Flappy Bird 小游戏。一个多小时，从零到能玩。接下来的画面是两个成年人对着电脑"啊——啊——啊——"地叫，声音忽高忽低，试图控制那只鸟不撞管子。满屋子回荡着荒诞的嚎叫声。他笑得不行。

但笑完之后他安静了。因为他意识到了一件事：**一个小时前，这个游戏不存在。现在它存在了。而且它是为我们两个人此刻的愉悦而存在的。**

然后当 Claude Code 帮他搭建了一个完全针对他业务场景的定制工具时——不是什么通用软件的配置，而是一个只为他的需求而存在的应用——他又安静了很久。

这验证了我在[上一篇](/when-software-becomes-disposable-zh)里写的"日抛型软件"判断：为一个人定制软件，在技术上已经完全可行。**但 99.99% 的人根本不知道可以提这个需求。**

他们从来没见过 Agent 级别的能力。他们用的是免费版的、被阉割的、被限速的模型。他们对 AI 的全部印象就是一个偶尔能给出有用答案的聊天框。

这不是技术问题。这是**认知问题**。

人们不知道什么是可能的。而当你不知道什么是可能的时候，你甚至不会去想要它。你不会要求你不知道存在的东西。

Boris Cherny 有一个产品术语来形容这件事：**潜在需求**（latent demand）。他说这是产品开发中最重要的一个概念。"人只会做他们已经在做的事。你不可能让人去做一件全新的事。如果人们在试图做一件事，而你让它变得更容易——这是好主意。但如果你试图让他们做一件不同的事，他们不会做的。"

这重新定义了认知鸿沟的本质——它是一个产品问题。我朋友不是没有需求——他已经在做财务分析了，已经在写报告了，已经在做投资决策了。需求一直都在。他缺的是"AI 能让这些事快十倍"的认知。一旦他亲眼看到——Claude Code 在他自己的数据上运行的那一刻——潜在需求瞬间变成了显性需求。差距不在动机，在曝光。

Claude Code 的每一个功能都是这样诞生的。Plan Mode？Boris 看到用户已经在跟 Claude 说"先想一下别写代码"——潜在需求。Claude.md？用户已经在自己写 markdown 文件让模型读——潜在需求。Cowork？非工程师已经在费尽周折安装终端版 Claude Code——潜在需求。模式始终一样：观察人们已经在试图做的事，然后移除摩擦。

最后一公里问题，本质上是一个潜在需求问题。需求存在——数十亿信息工作者的工作都可以被 Agent 改变。但他们不知道供给存在。你不会要求你从未见过的东西。

那潜在需求长什么样？这是一些 Boris 在访谈中提到的真实场景——全都不是编程：

**你每天都在做的重复工作。** Boris 自己用 Cowork 交停车罚款——Agent 帮他填表、上传证据、提交申诉。取消不用的订阅服务。管理团队周报——自动汇总各个人的进度。这些都是每个人都有但没人想做的事。

**数据分析和研究。** Anthropic 的数据科学家用 Claude Code 写 SQL、跑分析、生成图表。不是"帮我回答这个数据问题"——而是"这是我的数据库，帮我探索数据，找有意思的规律，写成报告"。Agent 会自己决定跑什么查询、怎么呈现。

**为你的具体场景定制工具。** [第四篇](/when-software-becomes-disposable-zh)讲的"日抛型软件"——不需要在市面上找一个"差不多能用"的通用产品，直接描述你的需求，让 Agent 给你做一个只为你服务的工具。我朋友那个周末就干了这件事：一个多小时，从零到一个完全为他的业务场景量身定制的应用。

**学任何你想学的东西。** 不是搜索引擎式的"X 是什么"——而是"我想理解 X，我的背景是 Y，用我能理解的方式解释，给我一个实际的例子，然后陪我一步步深入"。Agent 能根据你的知识水平调整解释深度，用你熟悉的类比，像一个有无限耐心的私人导师。

## 你才是 Manager

第三个发现最有趣，也最反直觉。

我朋友在学会基本操作之后，开始自己给 Claude Code 布置任务。他的指令是这样的：

"帮我分析一下这个。"

什么数据？分析什么维度？结论给谁看？用来做什么决策？格式要求？——全都没说。

Claude Code 当然可以猜。它会给出一个合理的默认分析。但这就像你对一个极其能干的新员工说"帮我弄一下那个东西"——你可能会得到一个结果，但几乎肯定不是你想要的结果。

**问题不在 AI 的能力——在人的管理能力。**

我花了半天时间教他的不是怎么用 Claude Code 的功能——而是怎么下指令。怎么把一个模糊的需求拆解成清晰的 spec。怎么提供足够的上下文。怎么定义成功标准。怎么在 Agent 给出第一版之后，给出有针对性的反馈而不是"不太对，再改改"。

这本质上是**管理培训**。

举个具体例子。比较这两种指令：

"帮我写一个 Python 脚本解析这个 CSV"——你在规定步骤。"我有一份销售数据，我需要知道哪些客户在过去三个月里下单频率下降了，以及可能的原因"——你在描述目标。让 Agent 决定怎么做，结果几乎总是比你预设路径要好。

上下文同样重要。你是谁，这个结果给谁看，你要用它来做什么决定。同一份数据，给老板看的和给投资人看的完全不同。Agent 不是读心术——你给的背景越多，结果越准。

我们一直在问"AI 能为你做什么"，但真正的问题是"你能为 AI 做什么"。你能不能提供清晰的需求？充分的上下文？如果你自己还没想清楚要什么，你能不能用 Agent 作为协作者来一起理清思路，而不是期待它读心术？

反过来想：如果你是一个 CEO，你的直属下属是一个能力极强但完全没有背景信息的人——你会怎么管理他？你不会说"帮我弄一下"。你会给他看数据，解释背景，定义目标，约定交付标准。

**对 AI 也一样。你才是 Manager。**

Boris 对此有一个让他自己都意外的观察。在 Anthropic 内部，更年轻、经验更少的工程师反而往往比资深工程师更会用 Claude Code。老工程师们根深蒂固的习惯和对"正确做法"的强烈主张，反而成了障碍。"最重要的能力是科学思维和第一性原理思考，"Boris 说，"过去那些强烈的技术观点很多已经不适用了。"

这对非工程师学用 Agent 同样适用。我朋友缺乏工程背景，这不完全是障碍——某种程度上反而是优势。他没有关于软件"应该怎么运作"的先入之见。一旦学会了管理技能——如何框定清晰的目标、提供充分的上下文——他不需要"忘掉"任何旧习惯。初学者心态，在 Agent 时代反而比专家心态更适合。

## 从工具到伙伴的认知跃迁

我朋友的心智模型在这个周末经历了三次跃迁。

**第一天**：搜索引擎。他问 Claude Code 问题，像用百度一样。"什么是 GCP？""怎么注册？"他在等答案。

**第一天晚上**：工具。他开始让 Claude Code 做事。"帮我写这个脚本。""把这个文件格式转一下。"他在使用工具。

**第二天结束**：协作者。他开始和 Claude Code 讨论。"我有一个想法，你觉得可行吗？""这个方案有什么我没想到的风险？""我们能不能换个思路？"他不再是在使用工具——他在和一个伙伴合作。

这三步跃迁——搜索引擎、工具、协作者——是整个市场需要经历的进化。

绝大多数人还在第一步。他们把 AI 当成一个更聪明的搜索引擎，给它一个问题，期待一个答案。少数人到了第二步，把 AI 当工具使用——但仍然是单向的、指令式的。极少数人到了第三步，把 AI 当成真正的协作伙伴。

这和我在[第一篇](/the-companion-vision-zh)里写的伴侣愿景是同一条线。一个真正理解你的 AI 伴侣，需要的不只是技术上的记忆编排和人格建模——**它需要一个愿意被理解的人。**

如果你不愿意提供上下文，不愿意说出真实想法，不愿意花时间和 Agent 建立共识——那再好的记忆系统也帮不了你。AI 伴侣的效果上限，不取决于 AI 的能力，取决于你投入的深度。

## 民主化的真正瓶颈

回到这个系列的主线。

[第二篇](/wearables-and-companions-zh)我写了"民主化高管生活方式"——每个人都应该有自己的私人教练和顾问。[第四篇](/when-software-becomes-disposable-zh)我写了"日抛型软件"和"3D 打印隐喻"——AI 让为一个人定制软件变得经济可行。

这些判断在技术上都成立了。

能力？已经到了。Claude Code 已经是最强的通用 Agent，几乎能处理任何电脑上的任务。

成本？入门级 20 美元一个月，一顿饭、几杯咖啡的钱。重度使用者需要 100 到 200 美元的 Max Plan，但即便如此——对比它能产生的价值，这个价格依然低得离谱。更不用说国内还有 Kimi、GLM、MiniMax 这些更便宜的选择，入门门槛还在持续降低。

**那为什么 Agent 革命还没有真正发生？**

因为瓶颈不在技术和成本——在**教育**。

99.99% 的人不知道 AI 能做什么。知道的人中，99% 不知道怎么有效地使用它。知道怎么使用的人中，大部分还没有建立起"AI 是协作者而不是工具"的心智模型。

这是一个**认知漏斗**。每一层都在大量流失。

Agent 革命不会被技术瓶颈卡住。不会被成本瓶颈卡住。**它会被教育瓶颈卡住。**

我这个周末的经历就是最好的例证。我朋友智商不低、动机不弱、学习能力不差——但他需要一个人坐在旁边，花两天时间，从搭环境到教心智模型，手把手带他跨过那道鸿沟。

规模化地做这件事——让数百万人跨过从"听说过 AI"到"真正用上 Agent"的鸿沟——这才是真正的难题。不是更好的模型，不是更便宜的价格，是教育。

但这里有一个更冷的现实：**AI 是认知差距的放大器。**

过去，一个聪明人和一个普通人的工作效率差距，也许是两三倍。但当聪明人学会了用 Agent，而普通人还在用搜索引擎——这个差距可能是一百倍。不是因为 AI 让聪明人变聪明了，而是因为 AI 把"会用的人"和"不会用的人"之间的鸿沟撕得更大了。

我朋友在这个周末跨过了鸿沟。但他是因为有一个恰好懂这些的朋友愿意花两天时间手把手教他。绝大多数人没有这个运气。

而且说实话——谁有动机去规模化地做这件事？教育从来不是一个好的商业模式。教一个人用 Agent 不产生直接收入。帮助别人跨过认知鸿沟没有 ROI 可算。做 Agent 工具的公司在优化产品，做 Agent 平台的公司在抢市场份额——没有人的 KPI 是"让更多人理解 AI 到底能干嘛"。

这是一个典型的公地悲剧：每个人都受益于更多人会用 AI，但没有人有足够的动机去承担教育成本。

## 教育体系的断层

而本该承担这个角色的机构——学校——完全没有准备好。

高等教育和现实脱节不是新闻。但 AI 时代，这个脱节变成了断裂。

我们的教育系统还在考记忆力。还在教学生用标准化的格式回答一些标准化的问题。背定义、套公式、默写要点——整个考核体系围绕的是"你能不能准确复述你被教过的东西"。

但这恰恰是 AI 最擅长的事。你花四年训练出来的记忆和复述能力，一个 Agent 用零点几秒就能做到，而且做得比你好。

教育系统几乎完全忽略了真正重要的东西：**独立思考的能力、做决定的能力、提出正确问题的能力、自驱力。**

在 AI Native 的时代，这些才是人的核心竞争力。会问正确的问题，比能回答问题值钱一百倍。有自己的想法和判断框架，比能背诵别人的想法重要一百倍。有内在驱动力去探索、去试错、去创造——这才是 Agent 替代不了的东西。

除了少数最前沿的学府在尝试转型，绝大多数学校甚至还没有开始思考这个问题。它们还在用工业时代设计的流水线，生产 AI 时代不再需要的产品。

这让最后一公里的问题更加棘手。不只是没有人有动机去教普通人用 AI——**连教育体系本身都在培养一种和 AI 时代相反的能力结构。** 它在训练人当执行者，而不是管理者。在训练人背答案，而不是问问题。

Boris 的招聘方式印证了这种倒转。他不找技术观点最强的人，也不看最漂亮的简历。他问一个问题："说一个你错了的例子。"他想看的是一个人能不能在事后认识到自己的错误，能不能承担责任，能不能从中学到东西。"很多非常资深的人永远不会真正承认一个错误，"他说，"但我大概一半的时候是错的。你只能不断去试。"教育体系奖励的是"答对"。Agent 时代奖励的是"知道自己什么时候错了"——然后快速迭代。

所以最后一公里可能会一直存在。不是因为技术不够好，不是因为价格不够低——而是因为没有人有足够的理由去铺这段路，而本该铺路的机构还在朝反方向走。

听起来残酷，但现实就是这样。
