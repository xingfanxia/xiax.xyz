---
title: "你才是 Manager"
date: "2026-02-22"
summary: "Agent 时代真正重要的技能不是编码——而是管理 AI。从下好指令到校准信任，这才是和 Agent 协作的真实样貌。"
tags: ["AI", "Agents"]
series: "AI智能体随想"
part: 6
type: "Post"
status: "Published"
---

## "帮我分析一下这个"

[第五篇](/the-last-mile-of-ai-zh)里，我讲了一个周末手把手教一个非工程师朋友用 Claude Code 的经历。基础设施的门槛很残酷，认知鸿沟更深。但第三个发现最反直觉。

我朋友在学会基本操作之后，开始自己给 Claude Code 布置任务。他的指令是这样的：

"帮我分析一下这个。"

什么数据？分析什么维度？结论给谁看？用来做什么决策？格式要求？——全都没说。

Claude Code 当然可以猜。它会给出一个合理的默认分析。但这就像你对一个极其能干的新员工说"帮我弄一下那个东西"——你可能会得到一个结果，但几乎肯定不是你想要的结果。

**问题不在 AI 的能力——在人的管理能力。**

我花了半天时间教他的不是怎么用 Claude Code 的功能——而是怎么下指令。怎么把一个模糊的需求拆解成清晰的 spec。怎么提供足够的上下文。怎么定义成功标准。怎么在 Agent 给出第一版之后，给出有针对性的反馈而不是"不太对，再改改"。

这本质上是**管理培训**。

举个具体例子。比较这两种指令：

"帮我写一个 Python 脚本解析这个 CSV"——你在规定步骤。"我有一份销售数据，我需要知道哪些客户在过去三个月里下单频率下降了，以及可能的原因"——你在描述目标。让 Agent 决定怎么做，结果几乎总是比你预设路径要好。

上下文同样重要。你是谁，这个结果给谁看，你要用它来做什么决定。同一份数据，给老板看的和给投资人看的完全不同。Agent 不是读心术——你给的背景越多，结果越准。

我们一直在问"AI 能为你做什么"，但真正的问题是"你能为 AI 做什么"。你能不能提供清晰的需求？充分的上下文？如果你自己还没想清楚要什么，你能不能用 Agent 作为协作者来一起理清思路，而不是期待它读心术？

反过来想：如果你是一个 CEO，你的直属下属是一个能力极强但完全没有背景信息的人——你会怎么管理他？你不会说"帮我弄一下"。你会给他看数据，解释背景，定义目标，约定交付标准。

**对 AI 也一样。你才是 Manager。**

Boris Cherny——Claude Code 的创造者——对此有一个让他自己都意外的观察。在 Anthropic 内部，更年轻、经验更少的工程师反而往往比资深工程师更会用 Claude Code。老工程师们根深蒂固的习惯和对"正确做法"的强烈主张，反而成了障碍。"最重要的能力是科学思维和第一性原理思考，"Boris 说，"过去那些强烈的技术观点很多已经不适用了。"

这对非工程师学用 Agent 同样适用。我朋友缺乏工程背景，这不完全是障碍——某种程度上反而是优势。他没有关于软件"应该怎么运作"的先入之见。一旦学会了管理技能——如何框定清晰的目标、提供充分的上下文——他不需要"忘掉"任何旧习惯。初学者心态，在 Agent 时代反而比专家心态更适合。

## 从工具到伙伴

我朋友的心智模型在这个周末经历了三次跃迁。

**第一天**：搜索引擎。他问 Claude Code 问题，像用百度一样。"什么是 GCP？""怎么注册？"他在等答案。

**第一天晚上**：工具。他开始让 Claude Code 做事。"帮我写这个脚本。""把这个文件格式转一下。"他在使用工具。

**第二天结束**：协作者。他开始和 Claude Code 讨论。"我有一个想法，你觉得可行吗？""这个方案有什么我没想到的风险？""我们能不能换个思路？"他不再是在使用工具——他在和一个伙伴合作。

这三步跃迁——搜索引擎、工具、协作者——是整个市场需要经历的进化。

绝大多数人还在第一步。他们把 AI 当成一个更聪明的搜索引擎，给它一个问题，期待一个答案。少数人到了第二步，把 AI 当工具使用——但仍然是单向的、指令式的。极少数人到了第三步，把 AI 当成真正的协作伙伴。

这和我在[第一篇](/the-companion-vision-zh)里写的伴侣愿景是同一条线。一个真正理解你的 AI 伴侣，需要的不只是技术上的记忆编排和人格建模——**它需要一个愿意被理解的人。**

如果你不愿意提供上下文，不愿意说出真实想法，不愿意花时间和 Agent 建立共识——那再好的记忆系统也帮不了你。AI 伴侣的效果上限，不取决于 AI 的能力，取决于你投入的深度。

## 你对模型能力的判断永远滞后

Boris 讲了一个让他自己也被迫重新校准认知的故事。有一次 Claude Code 出了内存泄漏，他按照老办法调试——取堆快照，在 DevTools 里分析，逐步排查。同时，团队里一个更年轻的工程师直接问 Claude Code："好像有内存泄漏，你能查一下吗？" Claude Code 自己取了堆快照，写了一个临时分析工具来解析数据，找到了泄漏点，提交了修复 PR——**比 Boris 手动调试更快**。他说自己必须不断提醒自己：现在的模型不是三个月前的模型了。你脑子里对模型能力的判断永远滞后于现实。

Boris 说他团队里最强的工程师呈现两种极端：一种是极致的专家，在某个领域理解得比任何人都深；另一种是超级通才，同时横跨产品、设计、用户研究和工程。工程师 Daisy 就是新范式思维的典型。她没有直接去实现一个功能，而是先让 Claude Code 造了一个"能测试任意工具"的工具——然后用这个元工具让 Claude 自己编写并验证了实际的功能代码。Boris 说："大多数人还没理解这种思维。"关键技能不再是写代码，而是想清楚怎么让 Agent 去解决问题。

**代码编写这个曾被视为核心技能的工作，正在变成 AI 的基础能力。** 程序员的竞争力正在从"写代码"转向"管理 AI 写代码"。

我自己的体验也是这样。我不再"写"代码——我描述我要什么，Claude Code 来实现。我审代码，做决策，给反馈。角色从程序员变成了项目经理。

## Agent 时代的三条原则

对于已经跨过那道门槛的人，这是 Boris 的三条进阶原则：

**校准你的信任。** 前面讲的内存泄漏故事有一个核心教训：**你对模型能力的判断永远滞后于现实。** 你觉得它做不到的事，试一下再说。最大的浪费不是给 Agent 太难的任务让它失败——而是你从来没给它机会去尝试你以为它做不到的事。

**保持指令精简。** Boris 自己的 Claude.md——控制 Claude Code 行为方式的配置文件——只有两行。一行是自动合并 PR，另一行是把 PR 发到团队 Slack 频道。就这些。他的建议是："删掉你的 Claude.md，从头开始。很多人把这件事过度工程化了。用最少的指令让模型走上正轨就好。每次模型更新，你需要写的指令就更少。"

**用更多 Agent 解决更难的问题。** Boris 根据任务难度来调整并行 sub-agent 的数量。简单的 bug？一个 Agent。中等复杂度？三个 Agent 并行研究。特别难的？五个甚至十个 Agent，每个从不同角度同时调查。核心洞察：向一个问题投入更多独立的上下文窗口，本身就是一种算力——Boris 称之为"不相关的上下文窗口"（uncorrelated context windows）。更多 Agent 意味着更强的能力，而不仅仅是更快的速度。

## 真正重要的问题

甚至招聘方式都在变。YC 正在尝试让工程候选人提交 Claude Code 会话记录——他们和 Agent 一起开发功能的完整过程。"你能看出一个人怎么思考，"YC 的合伙人说，"他们会不会看日志？Agent 跑偏了能不能纠正？会不会用 Plan Mode？有没有系统思维？"Boris 想做一个蜘蛛网图——像 NBA 2K 里那种——从系统思维、测试意识、产品直觉、自动化能力等维度给工程师打分。

Boris 自己的招聘方式也印证了这种转变。他不找技术观点最强的人，也不看最漂亮的简历。他问一个问题："说一个你错了的例子。"他想看的是一个人能不能在事后认识到自己的错误，能不能承担责任，能不能从中学到东西。"很多非常资深的人永远不会真正承认一个错误，"他说，"但我大概一半的时候是错的。你只能不断去试。"

问题不再是"你会不会写代码"，而是"你能不能驾驭 Agent 去构建需要的东西"。

工具已经在了。能力已经在了。瓶颈在你——你的管理能力，你的投入深度，你用目标而非步骤来思考的能力。

[第七篇](/why-claude-code-zh)退一步看更大的图景：为什么偏偏是 Claude Code 成了拐点，以及这一切意味着什么。
