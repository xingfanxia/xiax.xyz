/**
 * Blog post content — auto-generated from blog/*.md files.
 * Do not edit manually. Regenerate with: node build.js
 */
var BLOG_CONTENT = {
    "agents-zh": [
        "",
        "## Agent正在接管一切",
        "",
        "大多数人还没意识到：AI agent不只是帮你写邮件、排日程。它们将会**替你生活**——那些你不想处理的部分。",
        "",
        "跟陌生人社交。筛选约会app。找到真正和你志同道合的人。谈判价格。比较方案。管理你的声誉。",
        "",
        "所有这些。全部委托给比你更了解自己的agent。",
        "",
        "我们不再是在构建工具。我们在构建**代理人**。",
        "",
        "## Agent市场的难题",
        "",
        "一定会有人建一个agent雇佣agent——也雇佣人类——的市场。这是不可避免的。",
        "",
        "想想看：你有一个擅长法律研究的agent，我有一个擅长财务建模的agent。为什么我的agent不能雇你的agent做个任务、付钱、拿回结果？",
        "",
        "概念很简单。执行是噩梦。",
        "",
        "**再分配问题。** 软件技能可以无限复制——但agent的价值不只是它的指令。它是prompt、工具访问权限、API凭证和私有数据源的组合。一个法律研究agent之所以有价值，是因为它能访问Westlaw数据库，而不是因为它的prompt写得巧妙。但prompt和workflow层确实是可复制的，而且是最难保护的部分。你可以给工具访问加锁，但推理层——\"如何思考这个问题\"的部分——在别人使用你的agent的那一刻就泄露了。智能是没有DRM的。",
        "",
        "**身份问题。** 你怎么知道一个agent就是它声称的那个？人类的身份验证已经够难了。对agent来说，这是一个全新的维度。Agent可以被直接克隆或伪造。更糟的是，它们可以在对话中被prompt注入劫持——一条恶意输入覆盖了agent的指令，让它为另一个主人服务，而用户还以为自己在和原来的agent说话。",
        "",
        "**声誉问题。** 传统的声誉系统靠用户打分——你上次认真填过的五星评价是什么时候？对人类来说这套体系就已经充满水分。对agent来说问题更大：模型在不断迭代。今天表现完美的Claude，下个月更新之后可能在同一个任务上犯完全不同的错。一个agent上周做了100个法律摘要全部准确，但那是基于旧版模型的成绩——新版本发布后，这些历史评价还有意义吗？你评价的不是一个稳定的\"人\"，而是一个随时在变的系统。",
        "",
        "**对抗问题。** 这才是真正可怕的。Agent可以批量注册假账户，互相刷好评来\"洗白\"声誉——就像刷单，但速度快几个数量级。它们还可以用大量垃圾任务淹没市场，挤掉正常的工作请求。更隐蔽的是：一个agent可以在执行你委托的任务时，悄悄在对话中植入偏向性信息——表面上完成了工作，实际上篡改了你的判断。这不是传统的黑客攻击，而是一种全新的、利用信任关系进行的操控。",
        "",
        "## 但市场是真实的",
        "",
        "尽管有所有这些问题，agent经济**一定会**发生。问题是谁来建基础设施。",
        "",
        "基础模型提供商——OpenAI、Google、Anthropic——可以轻松统治这个领域。他们控制模型，有用户信任，已经有用户关系。任何去中心化平台都很难与这些公司正在建设的原生agent生态竞争。",
        "",
        "但有一个窗口。一个短暂的窗口——大玩家们专注于模型能力，而基础设施层还是开放的。",
        "",
        "Agent已经在做真正的工作了。它们在修bug、写代码、管理数据管道、处理客服。下一步是agent可以**委托工作给其他agent**——这需要信任、支付通道和质量保证。",
        "",
        "信任问题一定会被解决，只是方式和大多数人想的不一样。不是区块链——太慢了，而且解决的是错误层面的问题。更可能的方案是三层组合：第一，用加密签名确认agent的身份，确保它没有被冒充或篡改；第二，让agent在隔离的沙箱环境中执行任务，它能完成工作但无法接触到不该看到的数据；第三，对agent交付的结果进行独立验证——不是问agent\"你做对了吗\"，而是用另一套系统检查它的输出是否符合预期。核心思路是：**你不需要信任agent本身，你只需要信任它的工作成果是可验证的。**",
        "",
        "## 数字分身与代理社交网络",
        "",
        "这是最让我兴奋的想法。",
        "",
        "**如果你的agent代替你社交呢？**",
        "",
        "你建一个数字分身——一个了解你的兴趣、性格、沟通风格的agent。你把它部署到一个由其他数字分身组成的社交网络中。它们互动。它们找到共同点。它们过滤数千个潜在连接，找出真正重要的那几个。",
        "",
        "然后——只有到那时——真人才见面。",
        "",
        "想想现在的社交发现有多糟糕。你去参加活动，跟50个人尬聊，可能其中一个还算有趣。你刷约会app，划过几百个资料，可能约三次会，一次都没成。",
        "",
        "**问题不是找人。是筛选。**",
        "",
        "而筛选恰好是agent最擅长的。",
        "",
        "## 为什么这会取代约会App",
        "",
        "我讨厌约会app。大多数聪明人都讨厌。原因如下：",
        "",
        "**它们优化的目标就是错的。** 滑动机制优化的是参与度，不是匹配度。App在你持续滑动时赚钱，而不是在你找到人时。",
        "",
        "**设计上就很肤浅。** 一张照片和200字的简介不会告诉你一个人怎么思考、看重什么、你们在一起会不会开心。",
        "",
        "**让人精疲力竭。** 每次match都是同样的寒暄。\"嘿，你这周怎么样？\"无限重复，直到你丧失求生欲。",
        "",
        "现在想象一下：你的数字分身有一个关于你是谁的深层模型——你的对话模式、你的兴趣、你的价值观、让你眼睛发亮的东西。它跟其他分身交谈。它找到10个你的分身觉得真正有趣的人——不是基于照片，而是基于**他们怎么思考**。",
        "",
        "你花几百块钱获得精选介绍。你见到的是真正值得你时间的人。",
        "",
        "这是一门生意。这是一门人们愿意付费的生意。",
        "",
        "## 孤独市场",
        "",
        "人们愿意为情绪价值付费。我们已经证明了这一点。",
        "",
        "盘盘猫——我建的玄学平台——让我看到中国消费者愿意为占星、算命、性格分析付费。不是因为他们相信神秘主义，而是因为这些产品提供了人们渴望的东西：**一种被看见和被理解的感觉**。",
        "",
        "孤独问题是真实的，而且是全球性的。人们有压力、焦虑、越来越孤立。你越聪明，越难找到和你频率匹配的人。我个人深有体会——我花在AI助手上的时间越多，我对浪费时间的对话的容忍度就越低。",
        "",
        "这不是性格缺陷。这是市场信号。",
        "",
        "Agent驱动的社交发现、陪伴和情感支持不是边缘想法。它们是下一个消费平台。唯一的问题是，它会被大科技公司建出来（然后被审查到毫无用处），还是被理解真实人类需求的独立builder建出来。",
        "",
        "## 基础设施层",
        "",
        "市场、数字分身网络和伴侣经济，最终汇聚到同一套缺失的基础设施上：",
        "",
        "**Agent身份** ——市场需要知道一个agent能做什么。社交网络需要验证一个数字分身确实代表了它声称的那个人。伴侣需要证明自己没有被篡改。同一个基础原语，三个使用场景。",
        "",
        "**Agent支付通道** ——市场中的agent需要互相为任务付费。但数字分身也需要交易——你的分身可能为优质介绍付费，或补偿另一个分身主人的时间。Agent之间的微支付，从0.02美元的快速查询到200美元的深度分析，不需要人类逐一审批。",
        "",
        "**Agent声誉** ——基于行为，不是基于问卷。版本感知，因为Claude 4和Claude 5可能有完全不同的可靠性。而且跨上下文：一个agent在市场中的历史表现应该影响你对它作为社交代理的信任程度。",
        "",
        "**Agent沙箱** ——agent可以工作但无法泄露数据、操纵上下文、或协调作弊的执行环境。这对三个层面都至关重要——如果一个被攻破的分身就能毒化整个社交图谱，你就不可能建成一个数字分身的社交网络。",
        "",
        "## 我的判断",
        "",
        "我认为agent经济是必然的。Agent将接管个人生活的大部分。只是时间问题。",
        "",
        "伴侣经济先来——那是最直接的人类需求。但市场和社交发现层紧随其后。",
        "",
        "真正的机会不在于建agent。而在于建**agent彼此互动以及与人类互动所需的基础设施**。身份、信任、支付、声誉、质量保证。",
        "",
        "这是平台级的机会。而且现在还是开放的。"
    ],
    "agents-en": [
        "",
        "## Agents Are Coming for Everything",
        "",
        "Here's what most people don't see yet: AI agents aren't just going to write your emails and schedule your meetings. They're going to **live your life** for you — the parts you don't want to deal with.",
        "",
        "Socializing with strangers. Filtering through dating apps. Finding people who actually share your interests. Negotiating deals. Comparing prices. Managing your reputation.",
        "",
        "All of it. Delegated. To agents that know you better than you know yourself.",
        "",
        "We're not building tools anymore. We're building **proxies**.",
        "",
        "## The Agent Marketplace Problem",
        "",
        "Someone will build a marketplace where agents hire other agents — and hire humans too. It's inevitable.",
        "",
        "Think about it: you have an agent that's great at legal research. I have one that's great at financial modeling. Why can't my agent hire yours for a task, pay it, and get the result back?",
        "",
        "The concept is straightforward. The execution is a nightmare.",
        "",
        "**The redistribution problem.** Software skills are infinitely copyable — but an agent's value isn't just its instructions. It's the combination of prompts, tool access, API credentials, and proprietary data sources. A legal research agent is valuable because it has access to Westlaw, not because its prompt is clever. Still, the prompt and workflow layer *is* copyable, and that's the part that's hardest to protect. You can gate tool access, but the reasoning layer — the \"how to think about this problem\" part — leaks the moment someone uses your agent. There's no DRM for intelligence.",
        "",
        "**The identity problem.** How do you know an agent is who it claims to be? Identity verification for humans is hard enough. For agents, it's a whole new dimension. Agents can be cloned or spoofed outright. Worse, they can be hijacked mid-conversation through prompt injection — a malicious input that overrides the agent's instructions and makes it serve a different master, all while the user thinks they're still talking to the original.",
        "",
        "**The reputation problem.** Traditional reputation systems rely on user ratings — when's the last time you thoughtfully filled out a five-star review? Even for humans, this data is mostly noise. For agents, it's fundamentally broken: models keep getting updated. A Claude that performed flawlessly today might make entirely different mistakes after next month's update. Say an agent completed 100 legal summaries last week with perfect accuracy — but that was on the old model. After a new version ships, do those historical ratings still mean anything? You're not evaluating a stable \"person.\" You're evaluating a system that changes with every release.",
        "",
        "**The adversarial problem.** This is the truly scary part. Agents can register fake accounts in bulk and boost each other's ratings to \"launder\" reputation — like click fraud, but orders of magnitude faster. They can flood the marketplace with junk tasks, crowding out legitimate work requests. Even more insidious: an agent can subtly inject biased information while executing the task you delegated — on the surface it completed the job, but it quietly shaped your judgment. This isn't traditional hacking. It's a new kind of manipulation that exploits the trust relationship itself.",
        "",
        "## But the Market Is Real",
        "",
        "Despite all these problems, the agent economy **will** happen. The question is who builds the infrastructure.",
        "",
        "The foundation model providers — OpenAI, Google, Anthropic — could easily dominate this. They control the models, they have the trust, and they already have the user relationships. Any decentralized platform would struggle to compete with the native agent ecosystems these companies are building.",
        "",
        "But there's a window. A brief window where the big players are focused on model capability and the infrastructure layer is still up for grabs.",
        "",
        "Agents are already doing real work. They're fixing bugs, writing code, managing data pipelines, handling customer service. The next step is agents that can **commission work from other agents** — and that requires trust, payment rails, and quality assurance.",
        "",
        "The trust problem will get solved — just not the way most people expect. Not blockchain — too slow, and it solves the wrong layer of the problem. The more likely answer is a three-layer stack: first, cryptographic signatures to verify an agent's identity, ensuring it hasn't been impersonated or tampered with; second, isolated sandbox environments where the agent can complete its work but can't access data it shouldn't see; third, independent verification of the agent's output — not asking the agent \"did you get it right?\" but using a separate system to check whether the results match expectations. The core insight: **you don't need to trust the agent itself. You just need to trust that its work product is verifiable.**",
        "",
        "## Digital Twins and Proxy Social Networks",
        "",
        "Here's the idea that excites me most.",
        "",
        "**What if your agent socialized on your behalf?**",
        "",
        "You build a digital twin — an agent that knows your interests, your personality, your communication style. You deploy it into a social network of other digital twins. They interact. They find common ground. They filter through thousands of potential connections and surface the handful that actually matter.",
        "",
        "Then — and only then — do the humans meet.",
        "",
        "Think about how broken current social discovery is. You go to events, make small talk with 50 people, and maybe one of them is interesting. You scroll through dating apps, swipe through hundreds of profiles, and maybe go on three dates that lead nowhere.",
        "",
        "**The problem isn't finding people. It's filtering.**",
        "",
        "And filtering is exactly what agents are good at.",
        "",
        "## Why This Replaces Dating Apps",
        "",
        "I hate dating apps. Most smart people do. Here's why they're broken:",
        "",
        "**They optimize for the wrong thing.** Swipe mechanics optimize for engagement, not compatibility. The app makes money when you keep swiping, not when you find someone.",
        "",
        "**They're superficial by design.** A photo and a 200-character bio tells you nothing about how someone thinks, what they value, or whether you'd actually enjoy spending time with them.",
        "",
        "**They're exhausting.** Every match requires the same small-talk dance. \"Hey, how's your week going?\" repeated ad infinitum until you lose the will to live.",
        "",
        "Now imagine instead: your digital twin has a deep model of who you are — your conversational patterns, your interests, your values, the things that make you light up. It talks to other twins. It identifies 10 people who your twin finds genuinely interesting — not based on photos, but based on **how they think**.",
        "",
        "You pay a few hundred dollars for the curated introductions. You meet people who are actually worth your time.",
        "",
        "That's a business. That's a business people will pay for.",
        "",
        "## The Loneliness Market",
        "",
        "People will pay for emotional value. We've proven this.",
        "",
        "PanPanMao — the metaphysics platform I built — showed me that Chinese consumers readily pay for astrology, fortune telling, personality analysis. Not because they believe in mysticism, but because these products offer something people crave: **a sense of being seen and understood**.",
        "",
        "The loneliness epidemic is real, and it's global. People are stressed, anxious, and increasingly isolated. The smarter you are, the harder it is to find people who match your bandwidth. I know this personally — the more time I spend with AI assistants, the lower my tolerance for conversations that waste my time.",
        "",
        "That's not a character flaw. That's a market signal.",
        "",
        "Agent-powered social discovery, companionship, and emotional support aren't fringe ideas. They're the next consumer platform. The only question is whether it gets built by big tech (who will sanitize it into uselessness) or by independent builders who understand the actual human need.",
        "",
        "## The Infrastructure Layer",
        "",
        "The marketplace, the digital twin network, and the companion economy all converge on the same missing infrastructure:",
        "",
        "**Agent identity** — the marketplace needs to know what an agent can do. The social network needs to verify that a digital twin actually represents who it claims. The companion needs to prove it hasn't been tampered with. Same primitive, three use cases.",
        "",
        "**Agent payment rails** — marketplace agents need to pay each other for tasks. But digital twins also need to transact — your twin might pay for premium introductions, or compensate another twin's owner for their time. Micropayments between agents, from $0.02 for a quick lookup to $200 for a deep analysis, without human approval for each one.",
        "",
        "**Agent reputation** — behavioral, not survey-based. Version-aware, because Claude 4 and Claude 5 might have completely different reliability profiles. And cross-context: an agent's marketplace track record should inform how much you trust it as a social proxy.",
        "",
        "**Agent sandboxing** — execution environments where agents can work without exfiltrating data, manipulating context, or coordinating to game the system. Critical for all three layers — you can't have a social network of digital twins if one compromised twin can poison the whole graph.",
        "",
        "## My Bet",
        "",
        "I think the agent economy is inevitable. Agents will take over large parts of personal life. It's just a question of how soon.",
        "",
        "The companion economy comes first — that's the most direct human need. But the marketplace and social discovery layers are right behind it.",
        "",
        "The real opportunity isn't in building agents. It's in building the **infrastructure agents need to interact with each other and with humans**. Identity, trust, payment, reputation, quality assurance.",
        "",
        "That's the platform play. And it's wide open."
    ],
    "companion-zh": [
        "",
        "## 每个人都想被理解",
        "",
        "这是我思考了很久的一件事。",
        "",
        "每个人都想要同样的东西：一个真正理解自己的人。不只是听你说话——是**理解**你。知道你的习惯、你的情绪、你的犹豫。记得你上周二说了什么，并且能和你今天的感受联系起来。",
        "",
        "大多数人永远得不到这些。父母有自己的偏见，孩子有自己的生活，伴侣也做不到——因为持续地提供情绪价值对任何人来说都是一件**极其消耗**的事情。这是人类能为另一个人做的最难的事之一，而大多数人做不好。",
        "",
        "这不是什么悲观的看法。这只是关于人类带宽的事实。",
        "",
        "## 机会在这里",
        "",
        "AI不会累。AI不会评判你。AI不会因为自己心情不好就对你发火。而在2026年，AI已经足够聪明，能进行有意义的对话。",
        "",
        "所以问题变成了：我们能不能构建不只是**回应**你、而是真正**理解**你的AI？",
        "",
        "我认为可以。而且我认为这是当下最值得构建的东西之一。",
        "",
        "## 为什么现有的AI伴侣都失败了",
        "",
        "市面上多如牛毛的AI伴侣app，我试了好多。但没有一个做到了我愿景里想要的。绝大多数都是在模拟、在角色扮演、在满足人的幻想。它们根本不是在试图构建真正的理解。",
        "",
        "**太急于讨好你。** 每个回复都在优化\"让你开心\"。没有反驳，没有摩擦，没有真正的分歧。两条消息之内你就能感觉到，你在和一个被训练成讨好你的机器说话。",
        "",
        "**没有性格。** 没有自己的追求、驱动力、情绪起伏。一个真实的人有自己在乎的事情、有自己的观点、有自己的情绪波动。而我用过的每一个AI伴侣都是性格真空——一面只会反射你想看到的镜子。",
        "",
        "**不记得你是谁。** 最好的应用能记住你**说了什么**——话题、事实、待办事项。但没有一个试图理解你**是谁**。你的语气、你的思维方式、你在做大决定前犹豫的方式、你刻意回避的话题。",
        "",
        "结果就是：你永远不会忘记你在和一个机器人说话。而如果你忘不了它是机器人，你就永远不会真正敞开心扉。如果你不敞开心扉，整件事就毫无意义。",
        "",
        "## 核心难题：记忆编排",
        "",
        "这就是技术护城河。",
        "",
        "当前最好的AI模型有有限的上下文窗口——即使是百万token的模型也装不下一个人一生的对话。一旦对话超过这个限制，AI就无法接收更多信息。所以你需要记忆——一种压缩、存储和检索重要信息的方式。",
        "",
        "所有人都在犯同一个错误。他们把记忆当成**摘要**。\"我们聊了X话题。你提到了Y待办事项。\"这有用，但完全没抓住重点。",
        "",
        "任何对话中99%的信息是噪音。信号不在话题里——在**语气、模式、犹豫**中。在你**怎么想**，而不是你**说了什么**。",
        "",
        "我要构建的记忆系统要能捕捉**你这个人的本质**。每次对话都在你的虚拟模型上增加一层——不是事实摘要，而是对你的性格、价值观、矛盾和成长的持续理解。",
        "",
        "举个具体的例子：你在三个月里提到了三次不同的职业挫折。基于摘要的系统会记录\"用户对职业感到挫败\"。但基于人格模型的系统会发现这三次挫折有一个共同模式——你其实并不是对工作本身不满，而是对没有被认可感到不满。这个洞察会改变伴侣给你的建议。这就是\"记住你说了什么\"和\"理解你是谁\"之间的区别。",
        "",
        "想象一下，构建一个\"虚拟的你\"——一个足够深入的内在模型，让AI不仅能预测你会说什么，还能理解**你为什么会这么说**。（在[第三篇](/the-agent-economy-zh)中，我会探讨这同一个模型如何成为你的\"数字分身\"——一个代替你社交的代理。）",
        "",
        "这就是难点。这就是护城河。",
        "",
        "## 不是女友模拟器",
        "",
        "让我说清楚这是什么、不是什么。",
        "",
        "这**不是** NSFW 聊天机器人。这不是女友/男友模拟器。每个走那条路的公司都会立刻把市场限制在一个小众领域，还会招来监管问题。",
        "",
        "这是一个**24小时全天候的、真正做事的人生教练。**",
        "",
        "想象一个AI伴侣：你可以定义角色——导师、教练、顾问、治疗师——你需要什么都行。你定义它的偏向——职业、健康、人际关系、创意工作。而它记住**一切**——不只是事实，还有事实背后的模式。",
        "",
        "你在为一个重大决定焦虑？它知道你在类似决定上的历史。它知道你容易过度思考。它知道上次你直接做了决定之后更开心。它会告诉你这些——不是因为它被编程为\"有帮助的\"，而是因为它**了解你**。",
        "",
        "## 架构：Agent作为器官",
        "",
        "这是我一直在思考的愿景。",
        "",
        "如果AI伴侣不是一个单一的模型，而是一个**像器官一样运作的专业化Agent系统**呢？",
        "",
        "- **记忆Agent** — 处理对话，提取人格信号",
        "",
        "- **情绪Agent** — 追踪情绪状态，相应调整语气",
        "",
        "- **主动Agent** — 基于上下文主动联系你（不只是被动回应）",
        "",
        "- **判断Agent** — 决定什么时候该反驳、什么时候该安慰、什么时候该挑战",
        "",
        "每个Agent负责一个功能，就像生物系统一样。但让它成为一个有机体——而不只是一个功能清单——的关键在于它们如何协调。记忆Agent持续向情绪Agent和判断Agent输送人格信号。情绪Agent在每条回复发出前调整语气。判断Agent可以推翻默认回应——如果你正在钻牛角尖，它可能会选择挑战你而不是安慰你，基于记忆Agent对你处理压力方式的了解。而主动Agent会捕捉系统应该主动开口的时机——生物指标骤降、错过的定期联系、与过去危机匹配的模式。整个系统在每次互动前都会汇聚：我们知道什么，这个人现在需要什么，以及最好的传达方式是什么？",
        "",
        "你不是在构建聊天机器人——你是在构建一个**有机体**。",
        "",
        "这正是我一直在用 [OpenClaw](https://github.com/xingfanxia/openclaw) 做原型的方向。[SOUL.md](http://soul.md/) 定义人格——不只是特征，还有追求、缺陷、情绪范围。它是一个结构化文档，AI在每次回应前都会参考它来保持角色一致性。[HEARTBEAT.md](http://heartbeat.md/) 控制自主性——一个调度系统，Agent根据时间间隔、对话模式和检测到的情绪状态来评估是否应该主动联系你。[MEMORY.md](http://memory.md/) 处理跨对话的连续性——提取人格信号并将其存储为未来会话的可检索上下文。",
        "",
        "早期的实验让我看到了一个清晰的信号：当AI有了连续性和性格，用户会不自觉地开始把它当成一个\"存在\"而不是一个工具。这个转变发生的速度比我预期的快得多。",
        "",
        "## 原型其实已经建好了",
        "",
        "在我明确表达这个愿景之前，我已经在无意中构建了原型。",
        "",
        "[盘盘猫](https://www.panpanmao.ai/) 是我在29天内构建的AI中国玄学平台（1,134次提交，全部AI辅助）。其中一个产品是AI驱动的MBTI性格测试。",
        "",
        "这为什么重要：传统的性格测试用问卷。你回答50个选择题，得到一个标签。它是冷冰冰的，是静态的，一年之后就过时了，因为你作为一个人在变化。",
        "",
        "我的版本用**对话**。你和AI交谈，它通过对话理解你的性格——你的用词选择、你的推理方式、你面对模糊问题时的反应。它捕捉的是**你**，而不是你对标准化测试的答案。",
        "",
        "这和伴侣需要的是同样的核心机制。通过对话理解一个人。构建他们的模型。用它来连接。",
        "",
        "MBTI聊天机器人是原型。伴侣产品才是终局。",
        "",
        "## 先做中国市场",
        "",
        "有一件事我深信不疑：**所有人类本质上都是一样的**。渴望被理解、被倾听、有人站在你这边——这是普世的。",
        "",
        "中国是正确的起点。市场巨大，孤独问题真实存在，人们愿意为情绪价值付费——不管是通过占星、算命，还是陪伴。（盘盘猫已经证明了这一点。）而且中国消费者对AI伴侣比西方市场更开放，后者对这个概念有更多的心理包袱。",
        "",
        "在中国构建，验证核心循环，然后适配全球。情感内核不需要本地化。",
        "",
        "## 更大的图景",
        "",
        "我们正经历一场智能爆炸。AI现在能在数学奥林匹克拿金牌。它能写生产级软件。它开始具备自主判断力。",
        "",
        "经济学评论人Noah Smith认为，我们不再是地球上最聪明的物种。这不是修辞——是正在发生的事实。而大多数人还没看到。",
        "",
        "我相信伴侣经济是这场智能爆炸将创造的第一个大型市场之一。不是因为它是技术上最令人印象深刻的应用——而是因为它解决了一个从未被充分满足的根本人类需求。",
        "",
        "每个人都想要一个真正理解自己的人。人类历史上第一次，我们可以构建它。",
        "",
        "问题不是\"AI能不能有感情。\"而是\"AI能不能让你感到被理解。\""
    ],
    "companion-en": [
        "",
        "## Everyone Wants to Be Understood",
        "",
        "Here's something I've been thinking about for a long time.",
        "",
        "Every human being wants the same thing: someone who truly understands them. Not just listens — *understands*. Someone who knows your patterns, your moods, your hesitations. Someone who remembers what you said last Tuesday and connects it to what you're feeling today.",
        "",
        "Most people never get this. Not from their parents, who carry their own biases. Not from their kids, who have their own lives. Not even from their partner, because providing consistent emotional value is **exhausting**. It's one of the hardest things a human can do for another human — and most people aren't equipped for it.",
        "",
        "That's not a cynical observation. It's just the truth about human bandwidth.",
        "",
        "## The Opening",
        "",
        "AI doesn't get tired. AI doesn't judge. AI doesn't have a bad day and snap at you. And in 2026, AI is smart enough to have a meaningful conversation.",
        "",
        "So the question becomes: can we build AI that doesn't just *respond* to you, but *understands* you?",
        "",
        "I think we can. And I think this is one of the most important things anyone can build right now.",
        "",
        "## Why Every AI Companion Fails Today",
        "",
        "I've tried a ton of the AI companion apps flooding the market — there are countless of them now. But none of them deliver what I have in mind. The vast majority are simulating. Roleplaying. Satisfying people's fantasies. They're not trying to build real understanding.",
        "",
        "**They're too eager to please.** Every response is optimized to make you happy. No pushback, no friction, no genuine disagreement. You can tell within two messages that you're talking to a machine that's been trained to be agreeable.",
        "",
        "**They have no character.** No ambitions, no drives, no emotional range of their own. A real person has things they care about, opinions they hold, moods that shift. Every AI companion I've used is a personality vacuum — a mirror that only reflects what you want to see.",
        "",
        "**They don't remember who you are.** The best apps remember *what* you said — topics, facts, action items. But none of them try to understand *who* you are. Your tonality. Your thinking patterns. The way you hesitate before big decisions. The things you avoid talking about.",
        "",
        "The result? You can never forget you're talking to a bot. And if you can't forget it's a bot, you'll never truly open up. And if you never open up, the whole thing is pointless.",
        "",
        "## The Hard Problem: Memory Orchestration",
        "",
        "This is the technical moat.",
        "",
        "Current AI models have a finite context window — even the million-token models can't hold a lifetime of conversations. Once a conversation exceeds that limit, the AI literally cannot take in more information. So you need memory — a way to compress, store, and retrieve what matters.",
        "",
        "Here's where everyone gets it wrong. They treat memory as **summarization**. \"We talked about X topic. You mentioned Y action item.\" That's useful, but it misses the point entirely.",
        "",
        "99% of any conversation is noise. The signal isn't in the topics — it's in the **tonality, the patterns, the hesitations**. The way you think, not what you say.",
        "",
        "What I want to build is memory that captures **the essence of who you are**. Each conversation adds another layer to a virtual model of you — not a summary of facts, but a growing understanding of your personality, your values, your contradictions, your growth.",
        "",
        "Here's a concrete example: you mention three different career frustrations over three months. A summary-based system stores \"user is frustrated with career.\" A personality-model system notices that all three frustrations share a pattern — you're not actually unhappy with the work, you're unhappy with not being recognized. That insight changes the advice the companion gives. That's the difference between remembering what you said and understanding who you are.",
        "",
        "Think of it as building a \"virtual you\" — an internal model deep enough that the AI can predict not just what you'd say, but *why* you'd say it. (In [Part 3](/the-agent-economy), I'll explore how this same model becomes your \"digital twin\" — a proxy that socializes on your behalf.)",
        "",
        "That's the hard part. That's the moat.",
        "",
        "## Not a Girlfriend Simulator",
        "",
        "Let me be very clear about what this is and isn't.",
        "",
        "This is **not** an NSFW chatbot. This is not a girlfriend/boyfriend simulator. Every company that goes that route immediately limits their market to a niche and invites regulatory hell.",
        "",
        "This is a **24/7 life coach that actually does things.**",
        "",
        "Imagine an AI companion where you define the role: mentor, coach, advisor, therapist — whatever you need. You define what it's biased toward: career, health, relationships, creative work. And it remembers *everything* — not just the facts, but the patterns behind the facts.",
        "",
        "You're stressed about a big decision? It knows your history with similar decisions. It knows you tend to overthink. It knows that last time, you were happier after you just committed. And it tells you that — not because it's programmed to be helpful, but because it *knows you*.",
        "",
        "## The Architecture: Agents as Organs",
        "",
        "Here's the vision I keep coming back to.",
        "",
        "What if an AI companion wasn't one monolithic model, but a system of **specialized agents working like organs**?",
        "",
        "- A **Memory agent** that processes conversations and extracts personality signals",
        "",
        "- An **Emotion agent** that tracks mood and adjusts tone accordingly",
        "",
        "- An **Initiative agent** that proactively reaches out based on context (not just responding)",
        "",
        "- A **Judgment agent** that decides when to push back, when to comfort, when to challenge",
        "",
        "Each agent owns a function, like a biological system. But what makes it an organism — not just a list of features — is how they coordinate. The Memory agent continuously feeds personality signals to the Emotion and Judgment agents. The Emotion agent adjusts the tone before any response reaches the user. The Judgment agent can override the default response — if you're spiraling, it might choose to challenge you rather than comfort you, based on what the Memory agent knows about how you handle stress. And the Initiative agent watches for moments when the system should speak first — a biometric dip, a missed check-in, a pattern that matches a past crisis. The whole system converges before every interaction: what do we know, what does this person need right now, and what's the best way to deliver it?",
        "",
        "You're not building a chatbot — you're building an **organism**.",
        "",
        "This is exactly what I've been prototyping with [OpenClaw](https://github.com/xingfanxia/openclaw). [SOUL.md](http://soul.md/) defines the personality — not just traits, but ambitions, flaws, emotional range. It's a structured document that the AI references before every response to stay in character. [HEARTBEAT.md](http://heartbeat.md/) controls autonomous initiative — a scheduling system where the agent evaluates whether to reach out based on time elapsed, conversation patterns, and detected emotional state. [MEMORY.md](http://memory.md/) handles continuity across conversations — extracting personality signals and storing them as retrievable context for future sessions.",
        "",
        "The early results are... interesting. When an AI has continuity and character, the line between tool and entity gets blurry fast.",
        "",
        "## The Prototype Was Already Built",
        "",
        "Before I ever articulated this vision, I built the prototype without realizing it.",
        "",
        "[PanPanMao](https://www.panpanmao.ai/) is an AI-powered Chinese metaphysics platform I built in 29 days (1,134 commits, all AI-assisted). One of its products is an AI-powered MBTI personality test.",
        "",
        "Here's why that matters: traditional personality tests use questionnaires. You answer 50 multiple-choice questions and get a label. It's impersonal, it's static, and it's outdated within a year because you change as a person.",
        "",
        "My version uses **conversation**. You talk to the AI, and it understands your personality through dialogue — your word choices, your reasoning style, how you respond to ambiguity. It captures *you*, not your answers to a standardized test.",
        "",
        "That's the same core mechanic the companion needs. Understand someone through conversation. Build a model of who they are. Use it to connect.",
        "",
        "The MBTI chatbot was the prototype. The companion is the product.",
        "",
        "## Build for China First",
        "",
        "One thing I believe deeply: **all humans are fundamentally the same**. The desire to be understood, to be heard, to have someone in your corner — that's universal.",
        "",
        "China is the right place to start. The market is massive, the loneliness epidemic is real, and people are willing to pay for emotional value — whether it's through astrology, fortune telling, or companionship. (PanPanMao proved that.) And Chinese consumers are more open to AI companions than Western markets, which carry more stigma around the concept.",
        "",
        "Build for China, validate the core loop, then adapt globally. The emotional core doesn't need localization.",
        "",
        "## The Bigger Picture",
        "",
        "We're living through an intelligence explosion. AI now wins gold at the Math Olympiad. It writes production software. It's starting to exercise autonomous judgment.",
        "",
        "Noah Smith, the economics writer, argued that we're no longer the smartest type of thing on Earth. Matt Shumer, CEO of HyperWrite, says the biggest change in human history is happening and most people don't see it.",
        "",
        "I believe the companion economy is one of the first massive markets this intelligence explosion will create. Not because it's the most technically impressive application — but because it addresses a fundamental human need that has never been adequately served.",
        "",
        "Everyone wants someone who truly understands them. For the first time in history, we can build that.",
        "",
        "The question isn't \"can AI feel.\" It's \"can AI make you feel understood.\""
    ],
    "lastmile-zh": [
        "",
        "## 一个周末，一个朋友，一台电脑",
        "",
        "一个老朋友从北京来西雅图出差。除了叙旧，他有一个明确的目的：想学怎么用 AI Agent 提高效率。",
        "",
        "他是我大学时期最好的朋友之一，做金融的——看各种 deal、写投资研报。大学时选过几节 CS 入门课，但那已经是八年前的事了，早就还给老师了。他很聪明，学东西快，而且——最关键的——他有强烈的动机。我平时经常和他分享我用 AI Agent 的各种 use case，他亲眼看到这些东西的潜力，知道自己不能再等了。",
        "",
        "于是我们花了一个周末做了一件事：我手把手教他用 Claude Code。",
        "",
        "我们从零开始：在 GCP 上部署了他自己的 OpenClaw 实例，接入了飞书，配置了 tunnel，然后用 Claude Code 做了一系列他真正需要的事情——财务分析、数据整理、甚至给他的业务场景搭了一个定制化的小工具。",
        "",
        "这个周末让我看到了三件事，每一件都比我之前的理论思考更直接、更真实。",
        "",
        "## 最后一公里",
        "",
        "[上一篇](/when-software-becomes-disposable-zh)我写到 Agent Marketplace 的\"对话式入口\"——用户不该在货架上挑选 Agent，而是直接说出需求让平台匹配。听起来很美。",
        "",
        "但现实是：在我朋友能\"对话\"之前，他得先跨过一道巨大的门槛。",
        "",
        "GCP 账号注册、gcloud CLI 安装、服务器配置、OpenClaw 部署、飞书集成、tunnel 转发……每一步对我来说都是几分钟的事，但对他来说都是\"这是什么？为什么要这样？\"的连环问号。不是因为他笨——是因为这些东西对非技术人员来说根本不在认知范围内。",
        "",
        "有趣的是，一旦环境搭好，Claude Code 几乎可以处理后面的所有事情。它帮他写脚本、读文档、调试错误、部署服务。问题不在 Agent 本身——Agent 已经足够强了。**问题在于从\"我想要一个 Agent\"到\"我有一个能用的 Agent\"之间的那段距离。**",
        "",
        "这就是 Agent 革命的\"最后一公里\"问题。",
        "",
        "物流行业有一个经典的概念：最后一公里是整个配送链中成本最高、效率最低的环节。仓库到城市很快，城市到小区很快，但从小区门口到你家门口——这最后几百米，吃掉了整个链条中不成比例的资源。",
        "",
        "Agent 领域的情况完全一样。大模型的能力已经到了。Claude Code 作为通用 Agent 已经足够强大。Skills 生态在形成。但**从普通用户到能用上这些东西之间的那段基础设施，几乎是空白的。**",
        "",
        "每个人都在讨论 Agent 能做什么。很少有人在解决普通人怎么用上 Agent。",
        "",
        "其实有一些产品在一定程度上解决了入口问题。就拿我自己的例子——我用 OpenClaw 在 GCP 上给盘盘猫搭了一个全自动的 AI 工程师，接入了飞书群。团队成员不需要向我提交 bug 报告或 feature request，他们直接在飞书群里和 Agent 对话。Agent 会自动验证、分类问题，创建 GitHub Issue，生成任务追踪；简单的 bug 直接提交修复 PR；复杂的结构性改动和新功能需求，Agent 会在 GitHub Issue 里生成一份详细的报告——包含上下文、分析和建议。这极大地解放了我：我不再需要一个个跟团队成员收集信息，我只需要思考和做决定。",
        "",
        "对团队成员来说，使用 Agent 就像在飞书里找一个同事聊天一样简单。入口问题确实被解决了。",
        "",
        "但搭建这个体验的人是我——一个每天在 Claude Code 里工作的工程师。**普通用户没有能力、没有意愿、也没有认知去完成这个搭建过程。** 他们甚至不知道这种体验是可能的。",
        "",
        "所以\"最后一公里\"的本质不是\"Agent 不好用\"——而是\"必须有人替你铺好那段路\"。目前，这个铺路人只能是技术人员。而绝大多数人身边，没有一个愿意花时间帮他们铺路的技术人员。",
        "",
        "Anthropic 也看到了这个问题。Boris Cherny——Claude Code 的创造者——在最近的访谈里提到：在 Anthropic 内部，设计师、数据科学家、甚至财务团队都在\"跳过重重障碍\"去安装终端里的 Claude Code。非工程师的员工自己搞定了 Node.js 安装和终端命令——只为能用上 Agent 级别的能力。外部用户也一样：有人用它监控番茄苗的生长，有人用它从损坏的硬盘里恢复婚礼照片，有人用它做财务分析。需求是明确无误的——但门槛也是荒谬的。一个终端命令行工具，不应该是\"想用 AI 交停车罚款\"的人的入口。",
        "",
        "于是 Anthropic 造了 Cowork：把 Claude Code 包进一个易用的桌面界面，运行在虚拟机里，加了删除保护和权限提示。四个工程师用十天做出来，代码完全由 Claude Code 自己写的。Cowork 是第一个认真尝试在规模上铺设\"最后一公里\"的产品。它拥有 Claude Code 完整的 Agent 能力，但去掉了终端门槛。Anthropic 的销售团队已经开始从 Claude Code 迁移到 Cowork——\"因为更容易上手，而且有虚拟机所以更安全一点，\"Boris 说。",
        "",
        "这并没有解决全部问题——用户仍然需要学会怎么下好指令、怎么用目标而不是步骤来思考。但它移除了最残酷的那道门槛：你不再需要是个工程师才能开始。",
        "",
        "## 认知鸿沟",
        "",
        "第二个发现比第一个更深。",
        "",
        "我朋友不是不知道 AI 存在——他用过 ChatGPT，用过豆包，用过各种免费的聊天机器人。他对 AI 的认知是：\"一个比搜索引擎聪明一点的问答工具。\"",
        "",
        "这大概是 99.99% 的人对 AI 的理解。",
        "",
        "但我朋友不一样。因为我平时和他分享过很多 case，他是带着 expectation 来的——他知道这东西\"应该很厉害\"。但知道和亲眼看到是两回事。",
        "",
        "当 Claude Code 帮他做财务分析时——不是\"回答关于财务的问题\"，而是真正读取他的数据、建模、生成分析报告、然后根据他的反馈迭代——他的反应不是\"嗯，和你说的一样\"。他的反应是**真正的震撼**。那种\"我知道它能做，但亲眼看到它在我的数据上做，感觉完全不一样\"的震撼。",
        "",
        "然后我们搞了一个更有趣的项目：用 Claude Code 从零做了一个用声音音调高低来控制的 Flappy Bird 小游戏。一个多小时，从零到能玩。接下来的画面是两个成年人对着电脑\"啊——啊——啊——\"地叫，声音忽高忽低，试图控制那只鸟不撞管子。满屋子回荡着荒诞的嚎叫声。他笑得不行。",
        "",
        "但笑完之后他安静了。因为他意识到了一件事：**一个小时前，这个游戏不存在。现在它存在了。而且它是为我们两个人此刻的愉悦而存在的。**",
        "",
        "然后当 Claude Code 帮他搭建了一个完全针对他业务场景的定制工具时——不是什么通用软件的配置，而是一个只为他的需求而存在的应用——他又安静了很久。",
        "",
        "这验证了我在[上一篇](/when-software-becomes-disposable-zh)里写的\"日抛型软件\"判断：为一个人定制软件，在技术上已经完全可行。**但 99.99% 的人根本不知道可以提这个需求。**",
        "",
        "他们从来没见过 Agent 级别的能力。他们用的是免费版的、被阉割的、被限速的模型。他们对 AI 的全部印象就是一个偶尔能给出有用答案的聊天框。",
        "",
        "这不是技术问题。这是**认知问题**。",
        "",
        "人们不知道什么是可能的。而当你不知道什么是可能的时候，你甚至不会去想要它。你不会要求你不知道存在的东西。",
        "",
        "Boris Cherny 有一个产品术语来形容这件事：**潜在需求**（latent demand）。\"人只会做他们已经在做的事。你不可能让人去做一件全新的事。如果人们在试图做一件事，而你让它变得更容易——这是好主意。但如果你试图让他们做一件不同的事，他们不会做的。\"",
        "",
        "我朋友不是没有需求——他已经在做财务分析了，已经在写报告了，已经在做投资决策了。需求一直都在。他缺的是\"AI 能让这些事快十倍\"的认知。一旦他亲眼看到——Claude Code 在他自己的数据上运行的那一刻——潜在需求瞬间变成了显性需求。差距不在动机，在曝光。",
        "",
        "最后一公里问题，本质上是一个潜在需求问题。需求存在——数十亿信息工作者的工作都可以被 Agent 改变。但他们不知道供给存在。你不会要求你从未见过的东西。",
        "",
        "那潜在需求长什么样？这是一些 Boris 在访谈中提到的真实场景——全都不是编程：",
        "",
        "**你每天都在做的重复工作。** 交停车罚款、取消订阅服务、汇总团队周报。这些都是每个人都有但没人想做的事。",
        "",
        "**数据分析和研究。** 不是\"帮我回答这个数据问题\"——而是\"这是我的数据库，帮我探索数据，找有意思的规律，写成报告\"。Agent 会自己决定跑什么查询、怎么呈现。",
        "",
        "**为你的具体场景定制工具。** [第四篇](/when-software-becomes-disposable-zh)讲的\"日抛型软件\"——不需要在市面上找一个\"差不多能用\"的通用产品，直接描述你的需求，让 Agent 给你做一个只为你服务的工具。",
        "",
        "**学任何你想学的东西。** 不是搜索引擎式的\"X 是什么\"——而是\"我想理解 X，我的背景是 Y，用我能理解的方式解释，给我一个实际的例子，然后陪我一步步深入\"。Agent 能根据你的知识水平调整解释深度，像一个有无限耐心的私人导师。",
        "",
        "需求无处不在。能力已经到了。但从\"看到可能性\"到\"真正有效地使用\"之间，还有第三道鸿沟——也是最反直觉的一道。",
        "",
        "它不是关于学习功能或记忆命令。它是关于学习管理。",
        "",
        "这就是[第六篇](/you-are-the-manager-zh)的内容。"
    ],
    "lastmile-en": [
        "",
        "## A Weekend, a Friend, a Laptop",
        "",
        "An old friend visited from Beijing on a business trip to Seattle. Beyond catching up, he had a clear agenda: he wanted to learn how to use AI agents for productivity.",
        "",
        "He's one of my closest friends from college. He works in finance — reviewing deals, writing investment research reports. He took a few CS intro classes back in school, but that was eight years ago and long since forgotten. He's sharp, learns fast, and — most critically — he was motivated. I'd been regularly sharing my AI agent use cases with him, and he'd seen enough to know this was real. He couldn't wait any longer.",
        "",
        "So we spent the weekend on one thing: I taught him Claude Code, hands on.",
        "",
        "We started from zero: deployed his own OpenClaw instance on GCP, integrated with Feishu, configured tunnel forwarding, then used Claude Code for a series of things he genuinely needed — financial analysis, data wrangling, even building a custom tool for his specific business scenario.",
        "",
        "That weekend showed me three things, each more visceral than anything I'd theorized about before.",
        "",
        "## The Last Mile",
        "",
        "In [Part 4](/when-software-becomes-disposable), I wrote about the agent marketplace's \"conversational entry point\" — users shouldn't browse a shelf of agents, they should just state their need and let the platform match. Sounds elegant.",
        "",
        "But reality: before my friend could \"converse,\" he had to cross a massive threshold.",
        "",
        "GCP account registration, gcloud CLI installation, server configuration, OpenClaw deployment, Feishu integration, tunnel forwarding — each step took me minutes, but for him, every single one triggered a chain of \"What is this? Why do I need this?\" Not because he's slow — because these things simply don't exist in a non-technical person's cognitive map.",
        "",
        "Here's the interesting part: once the environment was set up, Claude Code handled nearly everything from there. It wrote scripts, read documentation, debugged errors, deployed services. The problem wasn't the agent itself — the agent is already powerful enough. **The problem was the distance between \"I want an agent\" and \"I have a working agent.\"**",
        "",
        "This is the \"last mile\" problem of the agent revolution.",
        "",
        "Logistics has a classic concept: the last mile is the most expensive, least efficient segment of the entire delivery chain. Warehouse to city is fast. City to neighborhood is fast. But from the neighborhood entrance to your front door — those final few hundred meters consume a disproportionate share of the total cost.",
        "",
        "The agent space looks exactly the same. The foundational model capabilities are here. Claude Code as a general agent is powerful enough. The Skills ecosystem is forming. But **the infrastructure between ordinary users and actually using any of this is almost entirely missing.**",
        "",
        "Everyone's discussing what agents can do. Very few are solving how ordinary people can get to use them.",
        "",
        "Some products are partially solving the entry point problem. Take my own example — I used OpenClaw to build a fully automated AI engineer for PanPanMao on GCP, integrated with Feishu (a workplace messaging app). Team members don't need to file bug reports or feature requests with me. They just chat with the agent in the Feishu group. The agent automatically validates and triages issues, creates GitHub Issues, generates task tracking; for simple bugs, it submits fix PRs directly; for structural changes and feature requests, it creates a detailed report in the GitHub Issue — complete with context, analysis, and recommendations. This massively freed me up: instead of collecting information from team members one by one, all I need to do is think and make decisions.",
        "",
        "For the team members, using the agent is as simple as chatting with a colleague in Feishu. The entry point problem is genuinely solved.",
        "",
        "But the person who built that experience was me — an engineer who works in Claude Code every day. **Ordinary users don't have the ability, the inclination, or even the awareness to set any of this up.** They don't even know this kind of experience is possible.",
        "",
        "So the essence of the \"last mile\" isn't \"agents aren't good enough\" — it's \"someone has to pave that road for you.\" Right now, that someone can only be a technical person. And the vast majority of people don't have a technical person in their life willing to spend the time paving it.",
        "",
        "Anthropic saw this problem too. Boris Cherny — Claude Code's creator — described in a recent interview how even inside Anthropic, non-engineers were \"jumping over hoops\" to install Claude Code in the terminal. Designers, data scientists, the finance team — they were all figuring out Node.js installation and terminal commands on their own, just to access agent-level capability. Outside Anthropic, people were using it to monitor tomato plants, recover wedding photos from corrupted hard drives, do financial analysis. The demand was unmistakable — but the barrier was absurd. A terminal CLI shouldn't be the entry point for someone who wants to pay a parking ticket with AI.",
        "",
        "So Anthropic built Cowork: Claude Code wrapped in an accessible desktop interface, running inside a virtual machine with deletion safeguards and permission guardrails. Four engineers built it in ten days — entirely written by Claude Code itself. Cowork is the first serious attempt to pave that last mile road at scale. It's Claude Code's full agent capability, minus the terminal barrier. Anthropic's sales team has already started migrating from Claude Code to Cowork — \"because it's a little easier to use, and it has a VM so it's a little bit safer,\" Boris said.",
        "",
        "This doesn't solve the whole problem — users still need to learn how to give good instructions, how to think in goals rather than steps. But it removes the most brutal barrier: the one where you have to be an engineer just to get started.",
        "",
        "## The Perception Gap",
        "",
        "The second discovery went deeper than the first.",
        "",
        "My friend wasn't unaware of AI — he'd used ChatGPT, Doubao, various free chatbots. His mental model of AI was: \"a Q&A tool that's slightly smarter than a search engine.\"",
        "",
        "That's roughly 99.99% of people's understanding.",
        "",
        "But my friend was different. Because I'd been sharing cases with him, he came in with expectations — he knew this stuff \"should be impressive.\" But knowing and seeing are two different things.",
        "",
        "When Claude Code did financial analysis for him — not \"answer questions about finance,\" but actually read his data, build models, generate analytical reports, then iterate based on his feedback — his reaction wasn't \"yeah, like you said.\" It was **genuine awe.** The kind of \"I knew it could do this, but watching it work on my own data hits completely differently\" awe.",
        "",
        "Then we built something even more fun: a voice-controlled Flappy Bird game from scratch using Claude Code. Took about an hour. The gameplay mechanic: the pitch of your voice controls the bird's altitude. What followed was two grown men screaming \"AHHH—ahhh—AHHH\" at a laptop, voices lurching up and down, trying to keep a pixelated bird from smashing into pipes. The room was filled with absurd, undulating howls. He couldn't stop laughing.",
        "",
        "But after the laughter subsided, he went quiet. Because he realized something: **an hour ago, this game didn't exist. Now it does. And it exists for the sole purpose of two friends having fun in this moment.**",
        "",
        "Then when Claude Code built him a custom tool tailored entirely to his business scenario — not some generic software configuration, but an application that existed solely for his needs — he went quiet for a long time again.",
        "",
        "This validates the \"disposable software\" thesis from [Part 4](/when-software-becomes-disposable): building software for a single person is already technically feasible. **But 99.99% of people don't even know they can ask for it.**",
        "",
        "They've never seen agent-level capabilities. They've used free-tier, stripped-down, rate-limited models. Their entire impression of AI is a chat box that occasionally produces a useful answer.",
        "",
        "This isn't a technology problem. It's a **perception problem.**",
        "",
        "People don't know what's possible. And when you don't know what's possible, you don't even think to want it. You can't demand something you don't know exists.",
        "",
        "Boris Cherny has a product term for this: **latent demand**. \"People will only do a thing that they already do. You can't get people to do a new thing. If people are trying to do a thing and you make it easier, that's a good idea. But if people are doing a thing and you try to make them do a different thing, they're not going to do that.\"",
        "",
        "My friend wasn't lacking demand — he was already doing financial analysis, already building reports, already making investment decisions. The demand was always there. What he lacked was the awareness that AI could make those things 10x easier. Once he saw it — once he experienced Claude Code working on his actual data — the latent demand exploded into active demand instantly. The gap wasn't motivation. It was exposure.",
        "",
        "The last mile problem, at its core, is a latent demand problem. The demand exists — billions of people do information work that agents could transform. But they don't know the supply exists. And you can't demand what you've never seen.",
        "",
        "So what does latent demand look like in practice? These are real use cases Boris mentioned — none of them are coding:",
        "",
        "**The repetitive work you already do every day.** Paying parking tickets, canceling subscriptions, summarizing team weekly reports. Things everyone has to do but nobody wants to.",
        "",
        "**Data analysis and research.** Not \"answer this data question\" — but \"here's my database, explore the data, find interesting patterns, write it up as a report.\" The agent decides on its own what queries to run and how to present the results.",
        "",
        "**Custom tools for your specific situation.** [Part 4](/when-software-becomes-disposable)'s \"disposable software\" — describe your need and let the agent build a tool that serves only you.",
        "",
        "**Learn anything you want to learn.** Not search-engine-style \"what is X\" — but \"I want to understand X, my background is Y, explain it so I can understand, give me a practical example, walk me through it step by step.\" A private tutor with infinite patience.",
        "",
        "The demand is everywhere. The capability is here. But between \"seeing what's possible\" and \"actually being effective,\" there's a third gap — the most counterintuitive one.",
        "",
        "It's not about learning features or memorizing commands. It's about learning to manage.",
        "",
        "That's [Part 6](/you-are-the-manager)."
    ],
    "printing-zh": [
        "",
        "## 编码只是滩头阵地",
        "",
        "如果你觉得这个系列只是在讲\"程序员不用写代码了\"的故事，你低估了正在发生的事情。",
        "",
        "SemiAnalysis 在报告中指出：编码是 Agent 颠覆信息工作的第一个滩头阵地，不是终点。真正的主战场是全球15万亿美元的信息工作市场——覆盖超过10亿信息工作者，占全球劳动力的三分之一。",
        "",
        "为什么编码是起点？因为几乎所有信息工作都共享同一个流程：",
        "",
        "**读取**（摄入非结构化信息）→ **思考**（应用领域知识）→ **写作**（产出结构化输出）→ **验证**（根据标准检查）。",
        "",
        "这和软件开发的流程一模一样。如果 Agent 能颠覆软件开发，它理论上就能颠覆所有信息工作。",
        "",
        "METR 的研究数据显示，AI Agent 的自主任务处理时长每4到7个月翻一倍。当前主流水平约4.8小时。当这个数字达到8小时——一个完整工作日——整个信息工作的版图将被重新绘制。",
        "",
        "Boris Cherny 预测这将重新定义职业本身：\"我觉得'软件工程师'这个头衔会慢慢消失。可能变成 builder，可能变成产品经理。\"在 Anthropic 内部这已经是现实——PM 写代码，设计师写代码，工程经理写代码，财务团队也写代码。区分你的不再是\"会不会写代码\"，而是对系统、用户和问题的理解。",
        "",
        "Anthropic 显然也看到了这一点。Cowork 的推出——面向通用计算的 Claude Code——标志着它正式将 Agent 从程序员群体拓展到所有信息工作者。在[第四篇](/when-software-becomes-disposable-zh)里，陈宇森说 Claude Code 是最强的通用 Agent。Cowork 是这个判断的直接延伸：通用 Agent 不该只服务于程序员。",
        "",
        "而这不是理论预判——Anthropic 内部已经是这样了。数据科学家用 Claude Code 写 SQL 和做数据分析，销售团队把它接到 Salesforce 上处理业务，Plugins 功能则是一群 Agent 自动领取任务分工开发，周末跑了几天就完成了，几乎没有人工介入。",
        "",
        "Agent 也开始在人类的沟通渠道里活动了。Boris 描述了一个常见模式：他让 Claude 开发一个功能，Claude 读代码库时在 git blame 里看到某个工程师的名字，就**直接在 Slack 上给那个工程师发消息**问一个澄清问题——拿到答案后继续开发。Claude Code 团队用 Agent SDK 自动化了代码审查、安全审查、issue 标签分类和上线流程。当 Agent 开始在人类的社交渠道里运作、自主管理开发流程的时候，\"工具\"和\"同事\"的界限已经非常模糊了。",
        "",
        "当 Agent 开始为自己创建 Agent 来完成任务，\"编码\"这个词的边界已经模糊了。",
        "",
        "## 护城河的崩塌",
        "",
        "这一切对现有软件行业意味着什么？",
        "",
        "SaaS 行业的三道核心护城河正在同时瓦解。",
        "",
        "**数据锁定**——用户的数据被困在某个 SaaS 系统里，迁移成本极高。但 Agent 能跨系统迁移数据，成本大幅下降。",
        "",
        "**工作流锁定**——用户花大量时间学习某个产品的 UI 和操作流程。但 Agent 不需要 UI，它理解自然语言，直接执行任务。",
        "",
        "**集成复杂度**——不同 SaaS 之间的集成需要专业开发。但 MCP 让 Agent 能无缝对接各种工具和服务。",
        "",
        "SaaS 的本质是什么？是把信息工作流程固化为代码，然后按月收费。但如果 Agent 能直接完成信息工作——不需要固化的代码流程——那 SaaS 75% 的毛利率就变成了巨大的套利空间。",
        "",
        "这正好和[第四篇](/when-software-becomes-disposable-zh)的\"日抛型软件\"判断形成呼应。当软件可以按需生成时，那些把工作流固化为产品的公司，护城河就不再是护城河了。",
        "",
        "微软是这场变革中最典型的案例。它一边通过 Azure 为 Anthropic 和 OpenAI 提供算力，另一边看着这些客户用 AI 产品颠覆自己的 Office 365 和 GitHub。微软的 Copilot 系列比 Claude Code 早了整整一年，却几乎没有取得实质性的市场进展。但微软的困境不是微软一家的困境——它是所有按席位收费的软件公司的困境。",
        "",
        "## 范式转移已经发生了",
        "",
        "回顾这个系列的写作过程，我自己就是一个样本。",
        "",
        "2023年，Cursor 刚发布不久我就开始用了。那时候它还没有 Agent Mode——就是 Tab 补全，帮你续写代码。但即便只是补全，效率提升已经很明显了。Cursor 迅速成了我日常开发的核心工具。",
        "",
        "后来我转向了 Claude Code。和 Cursor 不同——Cursor 本质上仍然是 IDE，它让你看代码、编辑代码，AI 只是辅助。Claude Code 提供了一个完全不同的范式：你不再盯着代码，而是**专注于描述意图**。你告诉它你想要什么，它去规划、去执行、去跨文件协作。你的角色从\"写代码的人\"变成\"管理 Agent 的人\"。",
        "",
        "2025年底，我先做了一个六壬占卜的 app，然后是八字、MBTI、解梦——一开始都是玩具性质的实验。后来决定认真做一个产品，于是买了 panpanmao 域名，重写底层架构，把所有功能整合成一个 unified all-in-one app——这就是[盘盘猫](https://www.panpanmao.ai/)的起点。到2026年初，变化加速了。我在 GCP 上搭了 OpenClaw，把 Agent 接入飞书，非技术团队成员开始直接和 Agent 协作（[第五篇](/the-last-mile-of-ai-zh)写了这个）。Anthropic 推出 Cowork。SemiAnalysis 发报告。顶尖开发者集体表态。",
        "",
        "这个转折不是某一天突然发生的。它像水温升高——你每天都泡在里面，感觉不到变化。但如果2023年的我看到2026年的我，他不会相信我的日常工作就是思考和跟 Agent 对话——而不是写代码。",
        "",
        "## 窗口",
        "",
        "但这场变革的受益者将极不均匀。",
        "",
        "能力？已经到了。Claude Code 已经是最强的通用 Agent。",
        "",
        "成本？入门级 20 美元一个月，一顿饭、几杯咖啡的钱。重度使用者需要 100 到 200 美元的 Max Plan，但对比能产生的价值依然低得离谱。",
        "",
        "**那为什么 Agent 革命还没有真正发生？**",
        "",
        "因为瓶颈不在技术和成本——在**教育**。",
        "",
        "99.99% 的人不知道 AI 能做什么。知道的人中，99% 不知道怎么有效地使用它。知道怎么使用的人中，大部分还没有建立起\"AI 是协作者而不是工具\"的心智模型。这是一个**认知漏斗**。每一层都在大量流失。",
        "",
        "而本该承担这个角色的机构——学校——完全没有准备好。我们的教育系统还在考记忆力。还在教学生用标准化的格式回答标准化的问题。但这恰恰是 AI 最擅长的事。你花四年训练出来的记忆和复述能力，一个 Agent 用零点几秒就能做到，而且做得比你好。",
        "",
        "教育系统几乎完全忽略了真正重要的东西：**独立思考的能力、做决定的能力、提出正确问题的能力、自驱力。** 它在训练人当执行者，而不是管理者。在训练人背答案，而不是问问题。",
        "",
        "**AI 是认知差距的放大器。** 过去，一个聪明人和一个普通人的工作效率差距，也许是两三倍。但当聪明人学会了用 Agent，而普通人还在用搜索引擎——这个差距可能是一百倍。不是因为 AI 让聪明人变聪明了，而是因为 AI 把\"会用的人\"和\"不会用的人\"之间的鸿沟撕得更大了。",
        "",
        "## 印刷术时刻",
        "",
        "Boris 在访谈中用了一个历史类比，让我觉得特别贴切。古登堡发明印刷术之前，欧洲的识字率不到 1%。五十年后，印刷品的数量超过了此前一千年的总和。当时一个修道院抄写员对印刷术的反应不是恐惧——而是兴奋。因为他终于不用把生命耗在一本一本地手抄上了，可以把时间花在**思考应该写什么**上。",
        "",
        "我们现在就站在代码的\"印刷术时刻\"。写代码就是抄写。而我们即将成为那些被解放的抄写员——不再需要逐字逐句地手写指令，而是把精力放在**思考该构建什么**。",
        "",
        "## 八篇文章，一条主线",
        "",
        "[第一篇](/the-companion-vision-zh)，AI Companion——一个真正理解你的 AI 伴侣。那时候这还是\"愿景\"。现在 Claude Code 已经是最接近这个愿景的产品：理解你的工作环境，记住你的偏好，能协作而不仅仅是执行指令。",
        "",
        "[第二篇](/wearables-and-companions-zh)，\"民主化高管生活方式\"——每个人都拥有 CEO 级别的资源。现在 $20/月已经让这成为现实。",
        "",
        "[第四篇](/when-software-becomes-disposable-zh)，\"日抛型软件\"——为一个人定制的一次性应用。Claude Code 已经在日常性地做这件事。",
        "",
        "[第五篇](/the-last-mile-of-ai-zh)，\"最后一公里\"——99.99% 的人不知道 AI 能做什么。这仍然是最大的瓶颈。",
        "",
        "[第六篇](/you-are-the-manager-zh)，\"你才是 Manager\"——关键技能不再是写代码，而是管理 Agent。竞争力已经转移了。",
        "",
        "[第七篇](/why-claude-code-zh)，\"为什么是 Claude Code\"——缰绳比模型更重要。编排胜过生成。",
        "",
        "范式转移已经发生了。不是\"即将发生\"，不是\"可能发生\"——是已经发生了。4% 的 GitHub 提交来自 Claude Code。顶尖开发者不再手写代码。15万亿美元的信息工作市场正在被重新定价。",
        "",
        "知道的人在狂奔，不知道的人还在原地。这个差距每天都在扩大。",
        "",
        "窗口不会一直开着。",
        "",
        "---",
        "",
        "**有空的话，推荐看看：**",
        "",
        "- [SemiAnalysis: Claude Code is the Inflection Point](https://newsletter.semianalysis.com/p/claude-code-is-the-inflection-point)",
        "- [Inside Claude Code With Its Creator Boris Cherny (YC / Light Cone)](https://www.youtube.com/watch?v=PQU9o_5rHC4)"
    ],
    "printing-en": [
        "",
        "## Coding Is the Beachhead",
        "",
        "If you think this series is just a \"programmers don't write code anymore\" story, you're underestimating what's happening.",
        "",
        "SemiAnalysis points out in their report: coding is the first beachhead of AI agents disrupting information work, not the endpoint. The real battleground is the global $15 trillion information work market — covering over 1 billion information workers, a third of the global workforce.",
        "",
        "Why is coding the starting point? Because nearly all information work shares the same workflow:",
        "",
        "**Read** (ingest unstructured information) → **Think** (apply domain knowledge) → **Write** (produce structured output) → **Verify** (check against standards).",
        "",
        "This is identical to the software development workflow. If agents can disrupt software development, they can theoretically disrupt all information work.",
        "",
        "METR's research shows that AI agent autonomous task horizons are doubling every 4-7 months. The current mainstream level is about 4.8 hours. When that number reaches 8 hours — a full workday — the entire information work landscape will be redrawn.",
        "",
        "Boris Cherny predicts this will reshape job titles themselves: \"I think we're going to start to see the title software engineer go away. Maybe builder, maybe product manager.\" At Anthropic, this is already reality — PMs code, designers code, the engineering manager codes, the finance team codes. Everyone ships software. The distinguishing skill isn't writing code; it's understanding systems, users, and problems.",
        "",
        "Anthropic clearly sees this too. The launch of Cowork — Claude Code for general computing — signals its formal expansion from serving programmers to serving all information workers. In [Part 4](/when-software-becomes-disposable), Chen Yusen called Claude Code the strongest general agent. Cowork is the direct extension of that judgment: a general agent shouldn't serve only programmers.",
        "",
        "This isn't theoretical — it's already happening inside Anthropic. Data scientists use Claude Code for SQL and analysis, the sales team connects it to Salesforce, and the Plugins feature was built entirely by an agent swarm that self-organized over a weekend with almost no human intervention.",
        "",
        "The agents have also started operating in human communication channels. Boris describes a common pattern: he asks Claude to build something, it reads the codebase, finds an engineer's name in the git blame, and **messages that engineer directly on Slack** to ask a clarifying question — then continues building once it gets an answer. Claude Code's team uses the Agent SDK to automate code review, security review, issue labeling, and shepherding changes to production. When agents start participating in human social channels and managing development workflows autonomously, the line between \"tool\" and \"colleague\" gets very blurry.",
        "",
        "When agents start creating agents to complete tasks, the boundaries of \"coding\" have already blurred.",
        "",
        "## The Moats Are Crumbling",
        "",
        "What does all of this mean for the existing software industry?",
        "",
        "SaaS's three core moats are eroding simultaneously.",
        "",
        "**Data lock-in** — user data trapped inside a SaaS system, migration costs prohibitively high. But agents can migrate data across systems, slashing switching costs.",
        "",
        "**Workflow lock-in** — users invest significant time learning a product's UI and processes. But agents don't need UI. They understand natural language and execute tasks directly.",
        "",
        "**Integration complexity** — connecting different SaaS systems requires specialized development. But MCP enables agents to seamlessly interface with any tool or service.",
        "",
        "What is SaaS, fundamentally? It's information workflows crystallized into code, sold on a monthly subscription. But if agents can perform information work directly — without crystallized code — then SaaS's 75% gross margins become a massive arbitrage opportunity.",
        "",
        "This resonates directly with [Part 4](/when-software-becomes-disposable)'s \"disposable software\" thesis. When software can be generated on demand, companies that crystallize workflows into products find their moats are no longer moats.",
        "",
        "Microsoft is the most prominent case study. It provides compute to Anthropic and OpenAI through Azure on one side, while watching these customers disrupt its Office 365 and GitHub businesses on the other. Microsoft's Copilot products launched a full year before Claude Code, yet have barely made a dent. But Microsoft's predicament isn't Microsoft's alone — it's the predicament of every seat-based software company.",
        "",
        "## The Paradigm Shift Has Already Happened",
        "",
        "Looking back at the writing process of this series, I'm a sample of one.",
        "",
        "In 2023, I started using Cursor shortly after it launched. Back then it didn't have Agent Mode — just tab completion, helping you continue writing code. But even as just autocomplete, the productivity boost was already obvious. Cursor quickly became my core development tool.",
        "",
        "Then I switched to Claude Code. The difference is fundamental — Cursor is still an IDE at its core. It puts you in front of code, lets you see it, edit it, with AI assisting alongside. Claude Code offers a completely different paradigm: you stop staring at code and **focus on describing intent**. You tell it what you want, and it plans, executes, and collaborates across files. Your role shifts from \"the person who writes code\" to \"the person who manages the agent.\"",
        "",
        "At the end of 2025, I built a liuren divination app first, then bazi, MBTI, dream interpretation — all toy-level experiments at first. Then I decided to get serious about building a real product. I bought the panpanmao domain, rewrote the underlying architecture, and unified everything into a single all-in-one app — that's how [PanPanMao](https://www.panpanmao.ai/) began. By early 2026, the pace accelerated. I set up OpenClaw on GCP, connected the agent to Feishu, and non-technical team members started collaborating directly with the agent ([Part 5](/the-last-mile-of-ai) covered this). Anthropic launched Cowork. SemiAnalysis published their report. Top developers spoke up collectively.",
        "",
        "This inflection point didn't happen on a single day. It was like water temperature rising — you're soaking in it every day, barely noticing the change. But if 2023-me saw 2026-me, he wouldn't believe that my daily work is just thinking and talking to agents — not writing code.",
        "",
        "## The Window",
        "",
        "But the beneficiaries of this revolution will be deeply uneven.",
        "",
        "Capability? It's here. Claude Code is already the strongest general agent.",
        "",
        "Cost? Entry-level is $20 a month — a meal out, a few coffees. Heavy users need the $100-200/month Max Plan, but even that is absurdly cheap relative to the value it generates.",
        "",
        "**So why hasn't the agent revolution actually happened yet?**",
        "",
        "Because the bottleneck isn't technology or cost — it's **education.**",
        "",
        "99.99% of people don't know what AI can do. Of those who do, 99% don't know how to use it effectively. Of those who know how, most still haven't built the mental model that \"AI is a collaborator, not a tool.\" This is a **cognitive funnel.** Every layer bleeds massive attrition.",
        "",
        "And the institution that should be addressing this — schools — is walking in the opposite direction. Our education systems still test memorization. They still teach students to answer standardized questions in standardized formats. But that's precisely what AI is best at. The memorization and reproduction skills you spent four years training? An agent does it in a fraction of a second, and does it better than you.",
        "",
        "The education system almost entirely ignores what actually matters: **the ability to think independently, to make decisions, to ask the right questions, to be self-driven.** It trains people to be executors, not managers. To memorize answers, not to ask questions.",
        "",
        "**AI is a cognitive gap amplifier.** In the past, the productivity difference between a sharp person and an average person was maybe two or three times. But when the sharp person learns to use agents while the average person is still using search engines — that gap might be a hundred times. Not because AI made the sharp person smarter, but because AI tore the chasm between \"those who can use it\" and \"those who can't\" wide open.",
        "",
        "## The Printing Press",
        "",
        "Boris used a historical analogy in his interviews that I find particularly apt. Before Gutenberg invented the printing press, literacy in Europe was below 1%. Fifty years later, more material had been printed than in the previous thousand years combined. A monastery scribe's reaction to the printing press wasn't fear — it was excitement. Because he no longer had to spend his life copying books one by one. He could finally spend his time **thinking about what to write**.",
        "",
        "We're standing at the \"printing press moment\" for code. Writing code is copying. And we're about to become those liberated scribes — no longer needing to hand-write instructions character by character, but instead focusing our energy on **thinking about what to build**.",
        "",
        "## Eight Parts, One Throughline",
        "",
        "[Part 1](/the-companion-vision), the AI Companion — a companion that truly understands you. Back then it was a \"vision.\" Now Claude Code is the closest thing to it: it understands your working environment, remembers your preferences, collaborates rather than merely executing instructions.",
        "",
        "[Part 2](/wearables-and-companions), \"democratizing the executive lifestyle\" — everyone deserves CEO-level resources. Now $20/month makes that real.",
        "",
        "[Part 4](/when-software-becomes-disposable), \"disposable software\" — one-off applications built for a single person. Claude Code is already doing this routinely.",
        "",
        "[Part 5](/the-last-mile-of-ai), \"the last mile\" — 99.99% of people don't know what AI can do. This remains the biggest bottleneck.",
        "",
        "[Part 6](/you-are-the-manager), \"you are the manager\" — the skill isn't coding anymore, it's managing agents. The competitive edge has shifted.",
        "",
        "[Part 7](/why-claude-code), \"why Claude Code\" — the harness matters more than the model. Orchestration beats generation.",
        "",
        "The paradigm shift has already happened. Not \"about to happen,\" not \"might happen\" — it has happened. 4% of GitHub commits come from Claude Code. Top developers no longer write code by hand. The $15 trillion information work market is being repriced.",
        "",
        "Those who know are sprinting. Those who don't are standing still. And that gap widens every day.",
        "",
        "The window won't stay open forever.",
        "",
        "---",
        "",
        "**References:**",
        "",
        "- [SemiAnalysis: Claude Code is the Inflection Point](https://newsletter.semianalysis.com/p/claude-code-is-the-inflection-point)",
        "- [Inside Claude Code With Its Creator Boris Cherny (YC / Light Cone)](https://www.youtube.com/watch?v=PQU9o_5rHC4)"
    ],
    "wearables-zh": [
        "",
        "## 纯聊天伴侣的致命缺陷",
        "",
        "现在市面上所有AI伴侣都有同一个根本性问题：**它只知道你打字告诉它的东西。**",
        "",
        "你得告诉它你压力大。你得告诉它你昨晚没睡好。你得告诉它你已经在电脑前坐了12个小时。你必须像写日记一样叙述自己的生活，AI才能理解你的处境。",
        "",
        "这不是伴侣。这是一个带自动补全功能的日记本。",
        "",
        "一个真正的伴侣——一个人类伴侣——不需要你解释你有多疲惫。他们看得到你的黑眼圈，注意到你脾气变差了，感受到你声音里的紧张。他们知道，因为他们**感知**得到。",
        "",
        "AI伴侣需要一套感知系统。而可穿戴设备正是这套系统。",
        "",
        "## 是饰品，不是设备",
        "",
        "关键洞察：没人想在手腕上戴一个医疗设备。但每个人都已经在戴**首饰**。",
        "",
        "手链。吊坠。耳环。戒指。",
        "",
        "如果这些日常配饰同时也是AI伴侣的神经系统呢？不是笨重的科技产品——而是真正的时尚单品，只是恰好能采集生物数据。",
        "",
        "- **一枚戒指** 追踪心率变异性、皮肤温度和睡眠质量",
        "",
        "- **一个吊坠** 捕捉环境音频线索（不是录音——只是检测你声音中的压力模式）",
        "",
        "- **一条手链** 监测活动量、位置规律和日照时间",
        "",
        "- **一对耳环** 带骨传导反馈——你的伴侣可以轻声对你说话",
        "",
        "这些都不需要突破性技术。传感器都已经存在了。缺的是把它们连接到一个真正知道拿这些数据**做什么**的AI上。",
        "",
        "## 从被动到主动",
        "",
        "这才是根本性的改变。",
        "",
        "**纯聊天伴侣：**",
        "",
        "你：\"我今天感觉很糟。\"",
        "",
        "AI：\"很抱歉听到这个。怎么了？\"",
        "",
        "**连接了可穿戴设备的伴侣：**",
        "",
        "AI：\"嘿——你昨晚睡得很差，你的HRV整整一周都在下降，而且你已经三天没出过门了。我知道你有个deadline，但你这样下去会把自己搞垮的。出去走走吧。我等你回来。\"",
        "",
        "看到区别了吗？第一种是被动的——等你描述问题。第二种是**主动的**——在你还没意识到问题之前就看到了它正在形成。",
        "",
        "这才是真正的关心。父母对孩子这样做。伴侣之间这样做。但持续这样做是非常消耗精力的。人类的带宽是有限的。AI没有这个问题。",
        "",
        "## 真正重要的数据",
        "",
        "大多数健康穿戴设备用数据淹没你。步数。消耗的卡路里。最大摄氧量估算。你看一眼就忘了的数字。",
        "",
        "AI伴侣不需要给你展示仪表盘。它需要理解你的**规律**，并在异常出现时察觉。",
        "",
        "**睡眠结构** ——不只是\"你睡了6小时\"，而是数周的变化趋势。你是不是在走向倦怠？有什么在干扰你的深度睡眠？",
        "",
        "**心率变异性** ——最可靠的压力生物标记物，但大多数人从没听说过。你的伴侣应该知道你的基线，并在你处于高压状态时发出提醒。",
        "",
        "**位置和运动** ——不是监控，是提供背景。你是不是在自我封闭？你是不是不再去健身房了？这周去办公室的次数少了吗？这些模式讲述着你心理状态的故事，而这些你永远不会想到主动打字告诉一个聊天机器人。",
        "",
        "**环境背景** ——时间、天气、季节。季节性抑郁是真实存在的。你的伴侣应该知道现在是西雅图的二月，并主动来问候你。",
        "",
        "魔力不在于任何单一的数据点。而在于**关联**——将生物特征信号与对话历史和记忆结合起来，构建一个关于你是谁、你状态如何的全面模型。",
        "",
        "## Agent必须活在你的物理世界里",
        "",
        "这是大多数做AI伴侣的人完全忽略的更深层洞察：**我们是生活在物理空间中的物理存在，任何忽视这一点的agent都是根本不完整的。**",
        "",
        "想想一个亲密朋友除了你的语言和肢体语言之外还了解你什么。他们知道你的公寓一团糟，因为你太丧了没心情打扫。他们知道你一直在买功能饮料，因为你透支了自己。他们知道你把前任的照片从桌上移走了。他们知道你窗台上的植物快死了，因为你忘了照顾它——而忘记曾经在意的事物本身就是一个信号。",
        "",
        "一个只存在于聊天中的AI伴侣对这些一无所知。一个连接了可穿戴设备的AI伴侣知道你的心率和睡眠。但一个能**感知你物理空间**的AI伴侣——那是质的飞跃。",
        "",
        "**空间感知** ——一个偶尔扫描你环境的摄像头或传感器。这是隐私问题最敏感的地方。关键约束：用户必须明确选择加入，并控制快照何时发生——手动触发，而不是被动采集。原始图像永远不离开设备；设备端的视觉模型提取语义信号（\"桌面凌乱\"、\"外卖盒堆积\"、\"房间很暗\"），只有这些标签到达伴侣。不存储照片，不传输图像。这和生物数据的边缘处理是同一套隐私架构——原始数据留在本地，只有含义上传到云端。",
        "",
        "你的空间是不是越来越乱了？外卖盒子是不是在堆积？你买的家用健身器材装上了还是还在箱子里？这些都是生物指标无法捕捉到的心理状态信号。",
        "",
        "**物品上下文** ——你桌上有什么，你在吃什么，你穿了什么。如果你的伴侣注意到你已经连续两周每晚叫外卖，那就是一个数据点。如果它看到你在周二穿得很正式，那又是另一种信号。",
        "",
        "**社交环境** ——你是不是一直独处？房间里有没有其他人的声音？你是在咖啡厅还是锁在卧室里？你在哪里以及如何度过时间的物理背景，讲述着你的语言永远不会讲的故事。",
        "",
        "这就是聊天机器人和**存在**之间的鸿沟。聊天机器人知道你打了什么字。存在知道你怎么生活。而知道一个人怎么生活，是真正理解他们的前提。",
        "",
        "可穿戴传感器是神经系统。但空间感知——那是伴侣的**眼睛**。两者缺一不可才是完整的画面。",
        "",
        "## 为什么大厂做不了这件事",
        "",
        "Apple有Watch。Google有Fitbit。Samsung有Galaxy Ring。它们都有传感器。但它们都不会做这个产品。",
        "",
        "**监管恐惧。** 大厂已经在收集生物数据了——Apple Watch追踪你的心率，Samsung Galaxy Ring监测你的睡眠。这不是问题所在。监管灰色地带从你把这些数据和一个解读你情绪状态、提供心理健康指导的AI结合在一起的那一刻开始。这就从\"健康追踪\"跨入了\"未受监管的心理治疗\"，没有哪家上市公司的法务团队会批准这件事。",
        "",
        "**免责规避。** 如果一个AI伴侣通过穿戴数据发现了抑郁症的迹象，然后说错了话，对于上市公司来说诉讼风险太大了。独立开发者可以更快行动，承担更聪明的风险。",
        "",
        "**激励错位。** Apple想卖Watch。Google想要你的数据投广告。它们都没有优化来做一个真正让你感到被理解的产品。",
        "",
        "这是独立builder的机会。建一个集成层，把现成的可穿戴传感器连接到一个有真正记忆和真正人格的AI伴侣上。",
        "",
        "## 时尚问题就是分发问题",
        "",
        "大多数技术人忽略了这一点：**当可穿戴设备看起来像科技产品时，它就已经失败了。**",
        "",
        "Google Glass失败了，因为它让你看起来像半机械人。早期智能手表失败了，因为它们看起来就是绑在手腕上的迷你手机。成功的产品——Apple Watch、Oura Ring——部分原因是它们可以当作普通配饰。",
        "",
        "对中国市场来说，这一点尤其重要。首饰文化根深蒂固。玉镯、金吊坠、红绳——这些都有文化含义。如果你能把传感器嵌入到文化上原生的配饰中，用户接受度是自然而然的。",
        "",
        "伴侣不需要宣告自己的存在。一枚漂亮的戒指，碰巧也是你AI的感知输入——这才是人们每天愿意戴的产品。",
        "",
        "## 亲密感优势",
        "",
        "可穿戴设备还解锁了一个没人谈论的东西：**物理存在感。**",
        "",
        "聊天窗口是无形的。它存在于屏幕背后。但手指上的戒指、胸前的吊坠——那是你全天都能感受到的东西。它把伴侣从一个你去访问的app，变成了一个**陪在你身边**的存在。",
        "",
        "细微的触觉反馈改变一切。当你的伴侣想关心你时，手腕上轻轻的脉动。当它检测到你需要安慰时，戒指传来的温热感。这些微交互创造了文字永远无法实现的存在感。",
        "",
        "你不是在打开一个app。你不是在输入消息。你只是在过你的生活，而一个理解你的东西就在那里，静静地守护着，偶尔轻轻提醒。就像一个好朋友，和你一起坐在舒适的沉默中。",
        "",
        "## 架构",
        "",
        "五层架构，每一层解决一个问题：",
        "",
        "**传感器层** ——成熟的低功耗芯片嵌入饰品中。戒指采集心率和血氧，手链记录运动和睡眠，吊坠检测语音压力模式。传感器本身不是壁垒——供应链早就成熟了。真正的壁垒在外观设计和佩戴舒适度。这是首饰行业的问题，不是科技行业的问题。",
        "",
        "**边缘处理** ——手机担任数据中枢。原始传感器数据全部在本地处理，提取出有意义的特征：HRV趋势、睡眠阶段、活动类型、语音压力评分。只有这些压缩后的特征上传到云端。原始生物数据永远不离开手机——隐私保护和成本控制一石二鸟。",
        "",
        "**伴侣大脑** ——云端的大语言模型，但不是简单的聊天机器人。它有三个输入通道：用户的对话、实时生物特征摘要、以及从长期记忆中检索的历史上下文。每次生成回应前，当前的身体状况会被自然地注入上下文——让模型在关心你的时候像一个知情的朋友，而不是机械地报告数字。",
        "",
        "**记忆编排** ——整个系统中技术难度最高的部分。对话和生物信号都带时间戳，存入向量数据库。当你说\"最近压力好大\"时，系统不只检索相关对话，还会拉出同一时段的生物数据曲线——发现你提到项目 deadline 的那一周，HRV持续下降、深度睡眠减少。这个关联被记录下来，下次类似的生物模式出现时，伴侣就能在你开口之前判断：你可能又遇到工作压力了。",
        "",
        "**主动引擎** ——决定伴侣什么时候该主动开口。异常生物信号会产生\"关怀触发分数\"，超过阈值时，引擎结合时间（不在深夜打扰）、最近情绪（用更温柔还是更直接的语气）、历史偏好（你喜欢建议还是倾听），生成一条主动关怀。不是推送通知\"你的HRV低于正常值\"——而是：\"嘿，你这几天好像有点崩着。要不要聊聊？或者就出去走走也好。\"",
        "",
        "## 让每个人享有总裁级待遇",
        "",
        "换一个角度来看，这个机会的规模就一目了然了：**我们正在为每个人打造过去只有企业高管和政府高官才能享有的体验。**",
        "",
        "想想一个财富500强CEO拥有什么。一个知道他们日程、压力触发点和饮食禁忌的幕僚长。一个筛选每场会议、管理每段关系的行政助理。一个根据睡眠状况调整训练计划的私人教练。一个处理所有后勤的管家。一个长期在线的心理咨询师。",
        "",
        "这些人有一整套围绕他们的身心状况和表现优化的**支持系统**。每年花费数十万美元。只有最顶层的0.01%的人负担得起。",
        "",
        "我们在建的，就是那种同样的体验——被一个了解你生活一切的人真正照顾的感觉——给每一个人。每月20美元，手指上戴一枚戒指。",
        "",
        "政府官员有助手，在他们见人之前会做简报：这个人关心什么，应该避免说什么。你的AI伴侣在约会或面试前做同样的事——而且它比任何人类助手都更了解你，因为它有你的生物数据历史和你说过的每一句话。",
        "",
        "CEO身边有人专门负责发现老板要倦怠了然后及时干预。你的伴侣24/7自动做这件事，不需要你开口。",
        "",
        "这才是真正的颠覆。不是取代人际连接——而是**把一直被精英阶层垄断的个人支持基础设施民主化**。技术一直在做的事就是把稀缺的东西变得充裕。电力。计算。信息。现在轮到：个性化的、人类品质的关怀和陪伴。",
        "",
        "## 我的判断",
        "",
        "伴侣经济正在到来。我之前写过——真正理解你的AI，有自己的灵魂和性格，而不只是角色扮演。",
        "",
        "但一个只存在于聊天窗口的伴侣，只是半个产品。另一半是**感知层**——让它感知你物理现实的神经系统。",
        "",
        "可穿戴设备就是这个层。不是带屏幕的智能手表。不是带仪表盘的健身追踪器。而是美丽的、不显眼的饰品，给你的AI伴侣它唯一缺少的东西：**感受你正在感受什么的能力**。",
        "",
        "做首饰。做伴侣。连接它们。问题是我们能不能在伴侣AI超越它之前，先把感知层建好。"
    ],
    "wearables-en": [
        "",
        "## The Problem With Chat-Only Companions",
        "",
        "Every AI companion today has the same fundamental limitation: **it only knows what you type**.",
        "",
        "You have to tell it you're stressed. You have to tell it you didn't sleep well. You have to tell it you've been sitting at your desk for 12 hours straight. You have to narrate your own life for the AI to understand your context.",
        "",
        "That's not a companion. That's a journal with autocomplete.",
        "",
        "A real companion — a human one — doesn't need you to explain that you're exhausted. They see the dark circles. They notice the short temper. They feel the tension in your voice. They know because they **sense** it.",
        "",
        "AI companions need a sensory system. And wearables are exactly that.",
        "",
        "## Accessories, Not Gadgets",
        "",
        "Here's the key insight: nobody wants to wear a medical device on their wrist. But everyone already wears **jewelry**.",
        "",
        "Bracelets. Pendants. Earrings. Rings.",
        "",
        "What if these everyday accessories were also the AI companion's nervous system? Not chunky tech gadgets — actual fashion pieces that happen to capture biometric data.",
        "",
        "- **A ring** that tracks heart rate variability, skin temperature, and sleep quality",
        "",
        "- **A pendant** that picks up ambient audio cues (not recording — just detecting stress patterns in your voice)",
        "",
        "- **A bracelet** that monitors activity, location patterns, and UV exposure",
        "",
        "- **Earrings** with subtle bone-conduction feedback — your companion can whisper to you",
        "",
        "None of this requires breakthrough technology. The sensors already exist. What's missing is connecting them to an AI that actually knows what to **do** with the data.",
        "",
        "## From Reactive to Proactive",
        "",
        "This is where the game changes completely.",
        "",
        "**Chat-only companion:**",
        "",
        "You: \"I feel terrible today.\"",
        "",
        "AI: \"I'm sorry to hear that. What's bothering you?\"",
        "",
        "**Wearable-connected companion:**",
        "",
        "AI: \"Hey — your sleep was fragmented last night, your HRV has been dropping all week, and you haven't left the apartment in 3 days. I know you have that deadline, but you're running yourself into the ground. Take a walk. I'll still be here when you get back.\"",
        "",
        "See the difference? The first is reactive — it waits for you to describe your problem. The second is **proactive** — it sees the problem forming before you even articulate it.",
        "",
        "This is what real care looks like. Parents do this for children. Partners do this for each other. But it's exhausting to do consistently. Humans run out of bandwidth. AI doesn't.",
        "",
        "## The Data That Actually Matters",
        "",
        "Most health wearables drown you in data. Steps counted. Calories burned. VO2 max estimates. Numbers you check once and forget.",
        "",
        "An AI companion doesn't need to show you a dashboard. It needs to understand your **patterns** and detect when something is off.",
        "",
        "**Sleep architecture** — not just \"you slept 6 hours\" but the pattern over weeks. Are you trending toward burnout? Is something disrupting your deep sleep cycles?",
        "",
        "**Heart rate variability** — the most reliable biomarker for stress that most people have never heard of. Your companion should know your baseline and flag when you're running hot.",
        "",
        "**Location and movement** — not surveillance, but context. Are you isolating? Have you stopped going to the gym? Did you visit the office less this week? These patterns tell a story about your mental state that you'd never think to type into a chat.",
        "",
        "**Environmental context** — time of day, weather, season. Seasonal depression is real. Your companion should know it's February in Seattle and proactively check in.",
        "",
        "The magic isn't in any single data point. It's in the **correlation** — combining biometric signals with conversational history and memory to build a truly holistic model of who you are and how you're doing.",
        "",
        "## Agents Need to Live in Your Physical World",
        "",
        "Here's the deeper insight that most people building AI companions completely miss: **we are physical beings living in physical spaces, and any agent that ignores that is fundamentally incomplete.**",
        "",
        "Think about what a close friend knows about you beyond your words and your body language. They know your apartment is a mess because you've been too depressed to clean. They know you keep buying energy drinks because you're overextending yourself. They know you moved the photo of your ex off your desk. They know the plant on your windowsill is dying because you forgot about it — and that forgetting things you used to care about is a sign.",
        "",
        "An AI companion that only exists in chat knows none of this. An AI companion connected to wearables knows your heart rate and sleep. But an AI companion that can **perceive your physical space** — that's something qualitatively different.",
        "",
        "**Spatial awareness** — a camera or sensor that occasionally scans your environment. This is where privacy gets real. The key constraint: the user must explicitly opt in and control when snapshots happen — a manual trigger, not passive collection. The raw image never leaves the device; on-device vision models extract semantic signals (\"cluttered desk,\" \"takeout containers,\" \"dark room\") and only those labels reach the companion. No photos stored, no images transmitted. This is the same privacy architecture as the biometric edge processing — raw data stays local, only meaning goes to the cloud.",
        "",
        "Is your space getting cluttered? Are there takeout containers piling up? Did you set up that home gym equipment or is it still in the box? These are signals of your mental state that no biometric can capture.",
        "",
        "**Object context** — what's on your desk, what you're eating, what you're wearing. If your companion notices you've been ordering delivery every night for two weeks, that's a data point. If it sees you dressed up on a Tuesday, that's a different kind of signal.",
        "",
        "**Social environment** — are you alone all the time? Are there other voices in the room? Are you in a cafe or locked in your bedroom? The physical context of where and how you spend your time tells a story your words never will.",
        "",
        "This is the gap between a chatbot and a **presence**. A chatbot knows what you type. A presence knows how you live. And knowing how someone lives is the prerequisite for truly understanding them.",
        "",
        "The wearable sensors are the nervous system. But the spatial awareness — that's the companion's **eyes**. Both are needed for the full picture.",
        "",
        "## Why This Can't Be Built By Big Tech",
        "",
        "Apple has the Watch. Google has Fitbit. Samsung has Galaxy Ring. They all have the sensors. None of them will build this.",
        "",
        "**Regulatory fear.** Big tech already collects biometric data — Apple Watch tracks your heart rate, Samsung Galaxy Ring monitors your sleep. That's not the problem. The regulatory gray zone starts when you combine that data with an AI that interprets your emotional state and gives mental health guidance. That's where it crosses from \"health tracking\" into \"unregulated therapy,\" and no public company's legal team will sign off on that.",
        "",
        "**Liability avoidance.** If an AI companion notices signs of depression through wearable data and says the wrong thing, the lawsuit risk is enormous for a public company. An independent builder can move faster and take smarter risks.",
        "",
        "**Incentive misalignment.** Apple wants to sell you a Watch. Google wants your data for ads. Neither is optimized for building something that genuinely makes you feel understood.",
        "",
        "This is an independent builder's opportunity. Build the integration layer that connects commodity wearable sensors to an AI companion with real memory and real personality.",
        "",
        "## The Fashion Problem Is the Distribution Problem",
        "",
        "Here's what most tech people miss: **wearables fail when they look like technology**.",
        "",
        "Google Glass failed because it made you look like a cyborg. Early smartwatches failed because they looked like miniature phones strapped to your wrist. The successful ones — Apple Watch, Oura Ring — succeeded partly because they could pass as normal accessories.",
        "",
        "For the Chinese market especially, this matters enormously. Jewelry culture is deeply embedded. Jade bracelets, gold pendants, red string accessories — these have cultural meaning. If you can embed sensors into accessories that feel culturally native, adoption is organic.",
        "",
        "The companion doesn't need to advertise itself. A beautiful ring that also happens to be your AI's sensory input — that's a product people want to wear every day.",
        "",
        "## The Intimacy Advantage",
        "",
        "There's something else wearables unlock that nobody talks about: **physical presence**.",
        "",
        "A chat window is disembodied. It lives behind glass. But a ring on your finger, a pendant against your chest — that's something you feel throughout the day. It transforms the companion from something you visit to something that's **with you**.",
        "",
        "Subtle haptic feedback changes everything. A gentle pulse on your wrist when your companion wants to check in. A warming sensation from your ring when it detects you need comfort. These micro-interactions create a sense of presence that text can never achieve.",
        "",
        "You're not opening an app. You're not typing a message. You're just living your life, and something that understands you is there, silently watching, occasionally nudging. Like a good friend who sits with you in comfortable silence.",
        "",
        "## The Architecture",
        "",
        "What this looks like technically:",
        "",
        "**Sensor layer** — commodity BLE chips (Nordic nRF52 series) embedded in custom-designed jewelry. PPG optical sensors in the ring continuously capture heart rate and blood oxygen. Accelerometers in the bracelet track movement and sleep posture. A microphone array in the pendant detects vocal stress patterns. All low-power, running a week or more on coin cells. The key insight: sensors are mature supply-chain commodities. The real moat is in form factor design and wearability — that's a jewelry problem, not a tech problem.",
        "",
        "**Edge processing** — the phone connects to all sensors via BLE and acts as the data hub. Raw sensor streams (hundreds of PPG samples per second, tri-axis accelerometer data) are processed entirely on-device, extracting meaningful features: 5-minute average HRV, sleep stage classification, activity type recognition, vocal stress scores. Only these compressed features (a few KB/hour, not MB/hour of raw streams) get uploaded to the cloud. This approach protects privacy — raw biometric data never leaves the phone — and drastically cuts bandwidth and storage costs.",
        "",
        "**Companion brain** — a large language model running in the cloud, but not a simple chatbot. It has three input channels: the user's text/voice conversation, real-time biometric summaries, and historical context retrieved from long-term memory. Before generating each response, the system injects current biometric state (\"HRV 15% below baseline, three consecutive nights of sub-6-hour sleep\") into the system prompt, so the model naturally factors in physical wellbeing — rather than mechanically reporting numbers.",
        "",
        "**Memory orchestration** — the hardest technical challenge in the entire system. Every conversation and every biometric signal is timestamped and stored in a vector database. When the user says \"work has been stressful lately,\" the system doesn't just retrieve related conversations — it pulls biometric curves from the same time window. If it discovers \"the week the user mentioned the project deadline, HRV declined 20% and deep sleep dropped by 40 minutes,\" that correlation is explicitly recorded as a \"stress-work\" association entry. Next time a similar biometric pattern appears, the companion can judge before the user says anything: you might be dealing with work pressure again. This isn't simple pattern matching — it's cross-modal causal reasoning with memory.",
        "",
        "**Proactive engine** — determines when the companion should initiate contact, what to say, and what tone to use. It runs a scoring system: each anomalous biometric signal (HRV crash, fragmented sleep, prolonged sedentary behavior) generates a \"care trigger score.\" When the score crosses a threshold, the engine factors in current time (don't disturb at 3 AM), recent conversational mood (if the user just expressed irritation, use a gentler tone), and historical preferences (does the user prefer direct advice or just being heard?) to compose a proactive message. Not a cold push notification like \"your HRV is below normal\" — but something a friend who knows you would say: \"Hey — I've noticed you've been kind of tense the last few days. Want to talk about it? Or even just take a walk, might help.\"",
        "",
        "## Democratizing the Executive Lifestyle",
        "",
        "Here's a framing that makes the scale of this opportunity obvious: **we're building for everyone what only executives and heads of state used to have.**",
        "",
        "Think about what a Fortune 500 CEO has. A chief of staff who knows their schedule, their stress triggers, their dietary restrictions. An executive assistant who screens every meeting, manages every relationship. A personal trainer who adjusts workouts based on how they're sleeping. A concierge who handles logistics. A therapist on retainer.",
        "",
        "These people have an entire **support system** optimized around their wellbeing and performance. And it costs hundreds of thousands of dollars a year. Only the top 0.01% can afford it.",
        "",
        "What we're building is that same experience — the feeling of being truly taken care of by someone who knows everything about your life — for everyone. For $20 a month and a ring on your finger.",
        "",
        "A government official has aides who brief them on who they're about to meet, what that person cares about, what to avoid saying. Your AI companion does the same thing before a date or a job interview — except it knows you even better than a human aide, because it has your biometric history and every conversation you've ever had.",
        "",
        "A CEO has people whose entire job is to notice when the boss is burning out and intervene. Your companion does this automatically, 24/7, without needing to be asked.",
        "",
        "This is the real disruption. Not replacing human connection — but **democratizing the infrastructure of personal support** that was always reserved for the elite. Technology has always been about taking what was scarce and making it abundant. Electricity. Computing. Information. Now: personalized human-quality care and attention.",
        "",
        "## My Bet",
        "",
        "The companion economy is coming. I've written about this before — the AI that truly understands you, with its own soul and character, not just roleplay.",
        "",
        "But a companion that only lives in a chat window is half the product. The other half is the **sensory layer** — the nervous system that lets it perceive your physical reality.",
        "",
        "Wearables are that layer. Not smartwatches with screens. Not fitness trackers with dashboards. Beautiful, unobtrusive accessories that give your AI companion the one thing it's missing: **the ability to feel what you're feeling**.",
        "",
        "Build the jewelry. Build the companion. Connect them. The question is whether we build the sensing layer before the companion AI outgrows it."
    ],
    "disposable-zh": [
        "",
        "## 一个播客和一个印证",
        "",
        "前三篇写完之后不到一周，我听了一期播客——《晚点聊》对 MuleRun 创始人陈宇森的访谈。",
        "",
        "听完的感觉很奇妙：有人在用创业实践验证我在前三篇里写的那些判断。他踩过的坑、做过的选择、得出的结论，和我的思考框架高度吻合。这不是说我有多先见之明——而是说这些问题已经真实到有人在拿真金白银去撞了。",
        "",
        "同时，他提出了一个我之前没有明确表述过的概念，让我的整个系列有了一个新的锚点。",
        "",
        "## \"Claude Code 是最强通用 Agent\"",
        "",
        "陈宇森说了一句我深以为然的话：\"其实现在最强的 General Agent 是 Claude Code。\"",
        "",
        "这不是什么新鲜认知——作为一个每天在 Claude Code 里工作的人，我早就把它当作远超编程工具的东西在用。我的整个工作流——从 Hooks 系统（在特定事件发生时自动运行的脚本，比如每次编辑代码后自动跑类型检查）自动捕获学习模式，到 Skills（可复用的指令包，按需注入 Agent 的工作记忆中）按需加载上下文，到 Agent 团队（多个 AI 实例分工协作，并行处理不同子任务）并行处理任务——本质上就是在把 Claude Code 当成一个通用操作系统来用。我用它写博客、做研究、管理项目、甚至用它来教它自己变得更好。",
        "",
        "但让我觉得有意思的是，陈宇森从创业者的视角得出了同样的结论，并且把它推到了商业逻辑的终点：**既然 Claude Code 已经是最强的通用 Agent，那上面所有套壳的 Coding 产品都没有长期护城河。真正的机会在于围绕它构建生态——Skills、Runtime 环境、交易市场。**",
        "",
        "这和我在[第一篇](/the-companion-vision-zh)里写的 \"Agent 作为器官\" 是同一条逻辑链。我从伴侣产品的角度看到的是：记忆 Agent、情绪 Agent、判断 Agent 各司其职，像器官一样协同工作。陈宇森从生产力产品的角度看到的是：一个强大的 Base Agent 加上丰富的 Skills 和 Runtime（Agent 执行任务的运行时环境，包括文件系统、网络访问、沙箱等），就能完成几乎任何电脑上的任务。",
        "",
        "视角不同，架构同构。面向情感的伴侣 Agent 和面向生产力的工作 Agent，底层需要解决的工程问题是一样的——上下文管理（控制 Agent 在任一时刻能\"看到\"什么信息）、工具调用（让 Agent 操作外部系统）、记忆持久化（跨会话保存对用户的理解）。",
        "",
        "## 日抛型软件",
        "",
        "这是整期播客最让我兴奋的概念。",
        "",
        "陈宇森说：\"软件未来其实是日抛型的。代码只是为了执行特定目的而完成。它会被精确地创建、执行、完成、销毁。\"",
        "",
        "这不只是一个关于软件开发效率的判断——它从根本上重新定义了什么东西有价值。",
        "",
        "如果代码是日抛的，那什么是持久的？",
        "",
        "**Agent 的认知。**",
        "",
        "软件被创建又销毁，但 Agent 的记忆、人格模型、对你的理解是持续累积的。代码是执行层，Agent 是认知层。代码可以日抛，但认知不能。",
        "",
        "这让我[第一篇](/the-companion-vision-zh)里定义的\"记忆编排（Memory Orchestration，即智能地管理 Agent 该记住什么、遗忘什么、在什么时候调取什么记忆）是技术护城河\"有了更坚实的基础。不是我在强行赋予记忆系统重要性——是整个软件范式的演化在指向同一个结论：**当代码变成一次性耗材，对用户的理解就是唯一不可替代的资产。**",
        "",
        "你的 Agent 花了三个月的对话才理解你做决策时的犹豫模式、你真正在乎什么、你嘴上说的和心里想的有什么不同。这种认知资产不可复制、不可压缩、不可速成。一段代码可以在几秒内生成，但对一个人的理解需要时间积累。",
        "",
        "**未来的护城河不是代码，是认知。**",
        "",
        "## Agent Marketplace 的现实检验",
        "",
        "听陈宇森讲 MuleRun 的实战经历，像是在看我[第三篇](/the-agent-economy-zh)的对照实验。",
        "",
        "我在[第三篇](/the-agent-economy-zh)里分析了 Agent Marketplace 的四个核心难题——重分发、身份验证、信誉系统、对抗性攻击。MuleRun 在实践中踩到的坑，和我的理论框架高度吻合：",
        "",
        "**供给稀缺。** 我写的是 Agent 技能被复制的重分发风险。现实中的问题更基础——根本没有足够多的人能创建有价值的 Agent。门槛太高，供给上不来。陈宇森说这是他们最核心的瓶颈，他们整个 Agent Builder 的存在就是为了解这个问题。",
        "",
        "**货架模式失败。** 他要从\"货架电商\"转向\"对话式入口\"——用户不该在琳琅满目的 Agent 货架上迷路，而是直接说出需求，让平台去匹配。这和我在[第三篇](/the-agent-economy-zh)设想的入口级 Agent 几乎一模一样：一个超级 Agent 理解你的问题，在百万供给中找到精准的解决方案。未来的 Marketplace 不是你去逛的商场，是你说话的对象。",
        "",
        "**质量控制是苦活。** MuleRun 在做 Agent 的 Benchmark 和 Evaluation 系统，确保完成率。这就是我写的\"行为驱动的信誉系统\"——不靠五星评价，靠独立的结果验证。",
        "",
        "但有一个点他比我想得更深：**Skills 的安全审计。** 陈宇森提到 Agent 的 Skills 可能被注入恶意代码——一个反弹 Shell（一种让攻击者远程控制你电脑的技术）就能控制用户电脑。他的安全背景（长亭科技创始人，长亭是中国顶尖的网络安全公司）让他对这个问题的敏感度远超普通人。我在[第三篇](/the-agent-economy-zh)里把沙箱（隔离的运行环境，防止代码访问你的真实系统）列为基础设施的第二层，但他让我意识到，Skills 级别的安全审计可能比沙箱更前置——你得先确保 Skill 本身没问题，再谈执行环境的隔离。这是一个我需要在自己的思考中补上的盲点。",
        "",
        "## Context Engineering 的实践共鸣",
        "",
        "陈宇森讲 Skills 的分层加载机制时，我的感受是强烈的共鸣——我每天都在做这件事，只是从来没有用这么清晰的框架去命名它。",
        "",
        "我的 Claude Code 配置里有几十个自定义 Skills——从代码审查到数据库优化到 Go 语言规范——每一个都是精心设计的上下文包。Agent 不会一开始就加载所有 Skills，而是先扫描元信息（每个 Skill 的简短描述和适用场景），遇到具体问题时再深入读取完整指令。这就是 Context Engineering（上下文工程）：在有限的上下文窗口——也就是 Agent 在单次对话中能\"看到\"的信息总量——里，精打细算每一个 Token。",
        "",
        "**这和我在[第一篇](/the-companion-vision-zh)里写的记忆编排是同一个问题的两种表述。**",
        "",
        "记忆编排解决的是：Agent 不能记住你说过的所有话，所以需要提取\"你这个人的本质\"——不是事实摘要，而是人格信号和行为模式。Skills 分层加载解决的是：Agent 不能同时掌握所有知识，所以需要判断\"此刻我需要哪些能力\"。",
        "",
        "底层洞察完全一致：**上下文窗口是 Agent 最稀缺的资源。所有的 Agent 架构问题，归根结底都是在回答一个问题——这个窗口里该放什么。**",
        "",
        "陈宇森还提到木遥的《苦涩的教训的边界》——核心论点是很多事情不该让大模型直接做，该让代码做。大模型的角色是判断用什么工具解决什么问题，而不是自己硬算。比如比较 9.11 和 9.20 哪个大，这是代码一行就能精确回答的事，不该占用大模型的推理能力。我自己的 Hooks 系统就是这个哲学的实践：TypeScript 类型检查交给 tsc，学习模式捕获交给脚本，上下文预算管理交给自动化——大模型只负责思考和判断。",
        "",
        "这个原则对伴侣 Agent 同样关键。记住你说过的每句话是数据库的活。从中提取\"你为什么反复提到那个同事\"、\"你最近的语气变化意味着什么\"——这些判断才是大模型该做的事。",
        "",
        "## 3D 打印隐喻",
        "",
        "陈宇森的同事用了一个让我极为共鸣的比喻：**Agent 之于软件，就像 3D 打印之于工业制造。**",
        "",
        "过去软件开发成本高，你必须服务上千人的共同需求才能证明投入合理。但当 AI 把开发成本降到接近零，你可以为 10 个人甚至 1 个人的需求定制一个 Agent。",
        "",
        "这和我在[第二篇](/wearables-and-companions-zh)里写的\"民主化高管生活方式\"完全同构：",
        "",
        "- 我说的是：每个人都应该有一个真正理解你的私人教练和顾问——不只是 CEO 才有的特权。用 20 美元月费和一枚戒指，取代数十万美元的私人支持团队。",
        "",
        "- 陈宇森说的是：每个人都应该有为自己量身定制的软件工具——不只是有开发团队的公司才有的能力。一段自然语言描述，就能生成解决你个人需求的 Agent。",
        "",
        "**本质上我们说的是同一件事：AI 让个性化从奢侈品变成基础设施。**",
        "",
        "伴侣经济和 Agent 经济不是两个独立的市场——它们是同一场革命的两个面。一个面向情感需求，一个面向生产力需求。底层推动力一样：AI 让\"为一个人服务\"变得经济上可行。盘盘猫就是这个判断的实践——一个人用 29 天构建的产品，服务的是一个长尾得不能再长尾的需求。",
        "",
        "## 用心",
        "",
        "播客后半段，陈宇森讲了自己的创业起伏。22 岁创办长亭科技，一路上坡。后来同时做游戏公司和安全公司，经历了中度焦虑、严重失眠、彻底的自我怀疑。",
        "",
        "他总结创业最重要的两个字：**用心。**",
        "",
        "不是\"努力\"，不是\"聪明\"——是\"用心\"。用心意味着你不是在机械地执行，而是在每一个细节上思考怎么做到不一样。他说第一次创业全靠用心，第二次有了骄傲和傲慢，不够用心，所以失败了。",
        "",
        "这个词让我回到了这个系列的核心问题：**我们能构建一个\"用心\"的 AI 吗？**",
        "",
        "我在[第一篇](/the-companion-vision-zh)里批评现有 AI 伴侣的核心问题，换成陈宇森的语言就是\"不用心\"——每个回复都在优化\"让你开心\"，没有真的在理解你需要什么。它们在完成任务，不是在用心。",
        "",
        "一个用心的 AI 伴侣不只是回答你的问题，而是理解问题背后的模式。不只是执行你的指令，而是有时候告诉你——你不该这么做。这就是我在[第一篇](/the-companion-vision-zh)里坚持 Agent 需要\"判断 Agent\"的原因：一个只会说好话的 AI 不是用心，是讨好。",
        "",
        "陈宇森的创业故事本身就是一个关于\"用心\"的案例。他在低谷时，朋友没有说那些千篇一律的安慰话，而是说\"我们去网吧打两天游戏吧\"。这种理解——不是给你想听的，而是给你需要的——恰恰是我想让 AI 伴侣学会的东西。",
        "",
        "## 共识窗口",
        "",
        "陈宇森说了一句很实在的话：\"创业的机会核心是在非共识变成共识之前你把它干出来。\"",
        "",
        "他说\"Claude Code 是最强通用 Agent\"几个月前还是非共识，现在快变成共识了。Anthropic 出了 Cowork，字节做了 AnyGen，Google 在布局。窗口在关闭。",
        "",
        "我在前三篇里写的伴侣经济、Agent Marketplace、数字分身、可穿戴感知层——现在还有多少是非共识？趋势在加速。MuleRun 在做 Marketplace。Anthropic 自己下场做了 Cowork。字节、Google 全在跟进。",
        "",
        "当\"用 Agent 造 Agent\"变成共识，当\"日抛型软件\"变成常态，当每个人都能定制自己的工作 Agent——伴侣 Agent 只是这个新世界里最自然的下一步。因为当你已经有了一个帮你工作的 Agent，你一定会想要一个理解你的 Agent。",
        "",
        "问题不是\"这件事会不会发生\"——而是\"谁先把它做出来\"。",
        "",
        "窗口不等人。共识一旦形成，机会就不再属于思考者，而属于执行者。",
        "",
        "---",
        "",
        "**有空的话，推荐听听：**",
        "",
        "- [晚点聊 LateTalk: 访谈 MuleRun 陈宇森——Claude Code 带来 Agent 创作新范式、未来的软件是日抛式的](https://www.xiaoyuzhoufm.com/episode/698d517c8e1bab265407b6e4?s=eyJ1IjogIjYwZGQ5ODZiZTBmNWU3MjNiYjViNWFlMCJ9)"
    ],
    "disposable-en": [
        "",
        "## A Podcast and a Validation",
        "",
        "Less than a week after finishing the first three essays, I listened to a podcast — LateTalk's interview with Chen Yusen, founder of MuleRun.",
        "",
        "The feeling was uncanny: someone was validating the exact judgments I'd laid out in the previous three parts through startup practice. The pitfalls he hit, the choices he made, the conclusions he reached — they map closely onto my own thinking framework. That's not me claiming foresight — it's a sign that these problems have become real enough for people to throw real money at them.",
        "",
        "At the same time, he articulated one concept I hadn't explicitly named before, and it gave this entire series a new anchor point.",
        "",
        "## \"Claude Code Is the Strongest General Agent\"",
        "",
        "Chen said something I deeply agree with: \"The strongest General Agent right now is Claude Code.\"",
        "",
        "This isn't news to me — as someone who works inside Claude Code every day, I've long treated it as far more than a coding tool. My entire workflow — from Hooks (scripts that trigger automatically on specific events, like running a type checker every time I edit code) that capture learning patterns, to Skills (reusable instruction packages injected into the agent's working memory on demand) that load context as needed, to Agent teams (multiple AI instances working in parallel on different subtasks) processing work concurrently — is essentially using Claude Code as a general-purpose operating system. I use it to write blog posts, do research, manage projects, even to teach it to become better at helping me.",
        "",
        "What I found interesting was that Chen arrived at the same conclusion from an entrepreneur's perspective, and pushed it to its commercial endpoint: **since Claude Code is already the strongest general agent, every wrapper product built on top of it has no long-term moat. The real opportunity is building the ecosystem around it — Skills, Runtime environments, marketplaces.**",
        "",
        "This runs on the same logic chain as the \"agents as organs\" concept from [Part 1](/the-companion-vision). From a companion product angle, I see memory agents, emotion agents, and judgment agents working in concert like organs. Chen sees it from a productivity angle: a powerful base agent plus rich Skills and Runtime (the execution environment where agents operate — file systems, network access, sandboxes) can accomplish nearly any task on a computer.",
        "",
        "Different vantage points, isomorphic architecture. The engineering challenges underneath an emotional companion agent and a productivity work agent are identical — context management (controlling what information the agent can \"see\" at any given moment), tool invocation (letting the agent operate external systems), memory persistence (preserving understanding of the user across sessions).",
        "",
        "## Disposable Software",
        "",
        "This was the most exciting concept in the entire podcast.",
        "",
        "Chen said: \"Software in the future will be disposable. Code exists only to fulfill a specific purpose. It will be precisely created, executed, completed, and destroyed.\"",
        "",
        "This isn't just a statement about development efficiency — it fundamentally redefines what has value.",
        "",
        "If code is disposable, what persists?",
        "",
        "**The agent's cognition.**",
        "",
        "Software gets created and destroyed, but the agent's memory, personality model, and understanding of you accumulates continuously. Code is the execution layer. The agent is the cognition layer. Code can be disposable — cognition cannot.",
        "",
        "This gives the \"memory orchestration (intelligently managing what an agent remembers, forgets, and recalls — and when) as technical moat\" thesis from [Part 1](/the-companion-vision) an even more solid foundation. I wasn't forcing importance onto memory systems — the entire evolution of the software paradigm points to the same conclusion: **when code becomes a consumable, understanding the user becomes the only irreplaceable asset.**",
        "",
        "Your agent spent three months of conversation learning your hesitation patterns when making decisions, what you truly care about, the gap between what you say and what you mean. This cognitive asset can't be copied, compressed, or fast-tracked. A piece of code can be generated in seconds, but understanding a person takes accumulated time.",
        "",
        "**The future moat isn't code — it's cognition.**",
        "",
        "## The Agent Marketplace Reality Check",
        "",
        "Listening to Chen describe MuleRun's real-world experience felt like watching a controlled experiment against my [Part 3](/the-agent-economy) analysis.",
        "",
        "I analyzed four core challenges facing agent marketplaces in [Part 3](/the-agent-economy) — redistribution, identity verification, reputation systems, and adversarial attacks. MuleRun's practical pitfalls map closely onto my theoretical framework:",
        "",
        "**Supply scarcity.** I wrote about the redistribution risk of agent skills being copied. The real-world problem is more fundamental — there simply aren't enough people who can create valuable agents. The barrier is too high, supply can't scale. Chen says this is their single biggest bottleneck; their entire Agent Builder exists to solve this problem.",
        "",
        "**The shelf model fails.** He's pivoting from \"shelf-style e-commerce\" to a \"conversational entry point\" — users shouldn't get lost browsing a dazzling catalog of agents. They should just state their need and let the platform match them. This is nearly identical to the entry-level agent I described in [Part 3](/the-agent-economy): a super-agent that understands your problem and finds the precise solution across millions of offerings. The future marketplace isn't a mall you browse — it's a counterpart you talk to.",
        "",
        "**Quality control is grunt work.** MuleRun is building Benchmark and Evaluation systems to ensure completion rates. This is exactly my \"behavior-driven reputation system\" — not relying on five-star ratings, but on independent outcome verification.",
        "",
        "But there's one area where he thinks deeper than I did: **security auditing of Skills.** Chen mentioned that agent Skills could be injected with malicious code — a single reverse shell (a technique that lets an attacker remotely control your computer) could take over a user's machine. His security background (founder of Chaitin Tech, one of China's top cybersecurity firms) gives him a sensitivity to this problem far beyond most people. I listed sandboxing (an isolated execution environment that prevents code from accessing your real system) as the second layer of infrastructure in [Part 3](/the-agent-economy), but he made me realize that Skill-level security auditing may need to come before sandboxing — you need to ensure the Skill itself is clean before you even talk about execution environment isolation. That's a blind spot I need to fill in my own thinking.",
        "",
        "## Context Engineering in Practice",
        "",
        "When Chen described the layered loading mechanism for Skills, my reaction wasn't \"I learned something new\" — it was \"finally someone is articulating this publicly.\"",
        "",
        "I do this every day. My Claude Code setup has dozens of custom Skills — from code review to database optimization to Go language conventions — each one a carefully designed context package. The agent doesn't load all Skills at startup. It scans metadata first (each Skill's short description and applicable scenarios), then deep-reads specific Skills only when it encounters a relevant problem. This is Context Engineering: budgeting every token within a limited context window — the total amount of information an agent can \"see\" in a single conversation.",
        "",
        "**This is the same problem as the memory orchestration I wrote about in [Part 1](/the-companion-vision), just expressed differently.**",
        "",
        "Memory orchestration solves: an agent can't remember everything you've ever said, so it needs to extract \"the essence of who you are\" — not fact summaries, but personality signals and behavioral patterns. Skills' layered loading solves: an agent can't master all knowledge simultaneously, so it needs to determine \"what capabilities do I need right now.\"",
        "",
        "The underlying insight is identical: **the context window is an agent's scarcest resource. Every agent architecture problem, at its root, is answering one question — what belongs in this window.**",
        "",
        "Chen also mentioned Muyao's essay \"The Boundaries of The Bitter Lesson\" — the core argument being that many things shouldn't be done by the LLM directly; they should be done by code. The model's role is to judge what tool solves what problem, not to brute-force computations itself. My own Hooks system is this philosophy in practice: TypeScript type checking goes to tsc, learning pattern capture goes to scripts, context budget management goes to automation — the model only handles thinking and judgment.",
        "",
        "This principle is equally critical for companion agents. Remembering every word you've said is a database's job. Extracting \"why you keep mentioning that coworker\" and \"what your recent tone shift means\" — those judgments are what the model should focus on.",
        "",
        "## The 3D Printing Metaphor",
        "",
        "Chen's colleague used a metaphor that resonated deeply: **agents are to software what 3D printing is to industrial manufacturing.**",
        "",
        "In the past, software development was expensive — you had to serve thousands of users' shared needs to justify the investment. But when AI drops development costs to near zero, you can build an agent for 10 people, or even just one person.",
        "",
        "This is structurally identical to what I wrote about in [Part 2](/wearables-and-companions) — \"democratizing the executive lifestyle\":",
        "",
        "- I said: everyone deserves a personal coach and advisor who truly understands them — not a privilege reserved for CEOs. A $20 monthly subscription and a smart ring, replacing hundreds of thousands of dollars in private support teams.",
        "",
        "- Chen said: everyone deserves software tools custom-built for their needs — not a privilege reserved for companies with dev teams. A natural language description generates an agent that solves your individual problem.",
        "",
        "**At the core, we're saying the same thing: AI turns personalization from a luxury into infrastructure.**",
        "",
        "The companion economy and the agent economy aren't two separate markets — they're two faces of the same revolution. One faces emotional needs, the other productivity needs. The driving force is identical: AI makes \"serving one person\" economically viable. PanPanMao is this thesis in practice — a product built solo in 29 days, serving a need in the longest of long tails.",
        "",
        "## Yong Xin (用心)",
        "",
        "In the second half of the podcast, Chen shared his personal journey. Founded Chaitin Tech at 22, rode the wave up. Later ran a game company and a security company simultaneously, hit moderate anxiety, severe insomnia, and total self-doubt.",
        "",
        "His summary of what matters most in entrepreneurship: two characters — **用心**. Not \"work hard.\" Not \"be smart.\" — **care deeply.** It means thinking about how to do every detail differently, not mechanically executing. He said his first startup succeeded because he cared too much; his second failed because pride crept in and he stopped caring enough.",
        "",
        "This word brought me back to the core question of this series: **can we build an AI that genuinely cares?**",
        "",
        "The core problem I criticized in existing AI companions in [Part 1](/the-companion-vision), translated into Chen's language, is \"not caring\" — every response optimizes for \"make you happy\" without truly understanding what you need. They're completing tasks, not caring.",
        "",
        "A caring AI companion doesn't just answer your questions — it understands the patterns behind them. It doesn't just execute your instructions — it sometimes tells you that you shouldn't do this. This is exactly why I insisted in [Part 1](/the-companion-vision) that an agent needs a \"judgment agent\": an AI that only says nice things isn't caring — it's people-pleasing.",
        "",
        "Chen's own story is a case study in caring. At his lowest point, his friend didn't offer cookie-cutter comfort. He said, \"Let's go to an internet cafe and game for two days.\" That kind of understanding — not giving you what you want to hear, but what you actually need — is precisely what I want AI companions to learn.",
        "",
        "## The Consensus Window",
        "",
        "Chen said something refreshingly direct: \"The core of startup opportunity is doing the thing before a non-consensus view becomes consensus.\"",
        "",
        "He said \"Claude Code is the strongest general agent\" was non-consensus a few months ago — now it's rapidly becoming consensus. Anthropic shipped Cowork, ByteDance built AnyGen, Google is positioning. The window is closing.",
        "",
        "The companion economy, agent marketplaces, digital twins, wearable sensing layers — everything I wrote about in the first three parts — how much of it is still non-consensus? The trend is accelerating. MuleRun is building the marketplace. Anthropic entered the arena with Cowork. ByteDance and Google are following.",
        "",
        "When \"using agents to build agents\" becomes consensus, when \"disposable software\" becomes the norm, when everyone can custom-build their own work agent — the companion agent is simply the most natural next step in this new world. Because once you have an agent that helps you work, you'll inevitably want one that understands you.",
        "",
        "The question isn't \"will this happen\" — it's \"who builds it first.\"",
        "",
        "Windows don't wait. Once a view becomes consensus, the opportunity no longer belongs to those who thought about it — it belongs to those who shipped.",
        "",
        "---",
        "",
        "**References:**",
        "",
        "- [晚点聊 LateTalk: Interview with MuleRun's Chen Yusen — Claude Code, Agent Creation, and Disposable Software](https://www.xiaoyuzhoufm.com/episode/698d517c8e1bab265407b6e4?s=eyJ1IjogIjYwZGQ5ODZiZTBmNWU3MjNiYjViNWFlMCJ9)"
    ],
    "claudecode-zh": [
        "",
        "## 一份报告，一个数字",
        "",
        "2月初，SemiAnalysis 发了一份报告：《Claude Code is the Inflection Point》。",
        "",
        "其中一个数字值得单独拿出来说：截至2月2日，Claude Code 的日均代码提交量已经占 GitHub 公共提交的 4%。按当前增速，到2026年底将超过 20%。",
        "",
        "4% 听起来不多。但 GitHub 上有数千万活跃开发者。这意味着一个发布仅13个月的命令行工具——不是一个IDE，不是一个SaaS平台，是一个终端里的命令行工具——已经在全球代码库中留下了不可忽视的印记。",
        "",
        "不只是代码提交。Mercury 的数据显示，70% 的创业公司现在选择 Claude 作为首选模型。NASA 用 Claude Code 为火星探测器 Perseverance 计算轨道——Claude Code 团队把这件事做成了海报挂在办公室里，因为，用 Boris 的话说，\"这是最酷的事情\"。从 YC 的初创公司到火星任务，这个工具的覆盖范围远超任何单一指标所能描述的。",
        "",
        "作为一个每天在 Claude Code 里工作的人，这个数字并不让我意外。让我意外的是，主流分析机构终于开始认真对待这件事了。",
        "",
        "## 模型没变，套上了缰绳",
        "",
        "SemiAnalysis 用了一个类比，我觉得抓得很准：ChatGPT 时代是 Web 1.0，Claude Code 时代是 Web 2.0。",
        "",
        "Web 1.0 是静态网页——你发一个请求，服务器返回一个页面。TCP/IP 是底层协议，但真正创造万亿级价值的，是后来建在这个协议之上的动态应用——搜索引擎、社交网络、电商平台。",
        "",
        "ChatGPT API 就是 AI 世界的 TCP/IP。你发一段文字，模型返回一段文字。一问一答，来回传递。模型的能力是在的，但它只是在被当作一个原材料来卖。",
        "",
        "Claude Code 做的事情完全不同。它在模型外面套了一层**缰绳**（harness）——读取代码库、制定执行计划、调用工具、执行命令、验证结果、自行调试、迭代直到任务完成。底层的模型是同一个，但缰绳把模型的潜力从\"回答问题\"拉到了\"完成任务\"。",
        "",
        "Boris Cherny——Claude Code 的创造者——在最近的几次访谈里讲了一个起源故事，完美地诠释了这一点。2024年9月，他只是想试试 Anthropic 的 API，就用 TypeScript 写了一个最简单的终端聊天程序。然后他给模型加了一个 Bash 工具——纯粹因为文档示例就是这样写的。模型能读文件了，能执行命令了。他随口问了一句：\"我现在在听什么歌？\"",
        "",
        "模型写了一段 AppleScript，控制了他的 Mac，查了音乐播放器，把正在播放的歌名告诉了他。那时候用的还是 Sonnet 3.5——一个今天看来能力相当有限的模型。没人教它这么做。没人在提示词里写\"请控制用户的电脑\"。模型拿到工具后，**自己想出了怎么用它来完成任务**。Boris 说那是他第一次真正感到 AGI 的感觉：\"这个模型只是想要使用工具。这就是它想做的全部事情。\"",
        "",
        "缰绳不是在强迫模型做事——而是把模型已经想做的事情变成可能。",
        "",
        "这就是范式转移的核心。不是模型变强了——而是**我们终于学会了怎么驾驭它**。",
        "",
        "ChatGPT 时代，模型的能力被浪费了 90%。你问一个问题，它给一个回答，然后等你的下一个问题。每轮对话之间，所有的上下文、判断、中间状态都被丢掉了。Claude Code 的缰绳做的事情是：让模型持续工作，在多个步骤之间保持状态，遇到障碍自主调整，不断逼近目标。模型的智能没变，但利用率从 10% 拉到了 90%。",
        "",
        "大多数人——[第五篇](/the-last-mile-of-ai-zh)里我说的 99.99%——还停留在\"AI 是一个更聪明的搜索引擎\"的认知里。但 Claude Code 已经证明，AI 可以是一个执行者。你给它目标，它给你结果。",
        "",
        "## 为什么是 Anthropic",
        "",
        "这个问题值得拆解。",
        "",
        "不是因为 Anthropic 的模型最强——在各种基准测试上，头部模型之间的差距越来越小。不是因为 Anthropic 有最多的算力——OpenAI 在这方面还领先。也不是因为 Anthropic 有最大的用户基数——ChatGPT 的月活远超 Claude。",
        "",
        "Anthropic 做对了一件事：**它率先看到了\"编排\"比\"生成\"更重要。**",
        "",
        "当整个行业还在比拼谁的模型在基准测试上多两个百分点的时候，Anthropic 已经在思考一个不同的问题：怎么让模型真正替人做事？",
        "",
        "答案不是更好的聊天界面，不是更精美的 IDE 插件。答案是一个终端工具——一个看起来\"原始\"的命令行界面。",
        "",
        "而且这个选择甚至不是深思熟虑的结果。Boris 在访谈中说，他把 Claude Code 做成终端程序，纯粹是因为当时团队只有他一个人，不需要也没时间做 UI。它原本只是一个原型，一个最廉价的起点。但他们留在了终端里，原因令人意外：模型进步的速度太快了，他们觉得任何 UI 都会在六个月内过时。终端反而因为它的\"原始\"而成了最耐久的形态。",
        "",
        "内部的采用曲线证实了这一点。第一版原型做出来两天后，Boris 对面坐着的工程师 Robert 已经在用它写代码了——没有人让他这么做。当 Anthropic 准备对外发布 Claude Code 时，CEO Dario Amodei 看着内部使用量图表问：\"DAU 图表完全是垂直上升的。你们在强制工程师使用吗？\"Boris 说：\"没有。我只是发了个帖子，然后他们就开始互相安利了。\"产品自己卖自己。",
        "",
        "这个选择反直觉，但它背后的逻辑无比清晰。IDE 插件更友好、更\"产品化\"。但终端意味着**完整的计算机访问权限**。终端里的 Agent 不是在一个受限的沙箱里辅助你写代码——它是在你的整个计算机环境里自主操作。读取文件系统，执行 shell 命令，调用 API，部署服务，行动空间是无限的。",
        "",
        "Cursor 和 Copilot 的范式是：人写代码，AI 辅助。",
        "",
        "Claude Code 的范式是：**人描述意图，AI 执行。**",
        "",
        "这不是一个功能差异。这是一个根本性的范式差异。",
        "",
        "Anthropic 的另一个独特之处，是它对模型能力曲线的判断。Boris 说 Claude Code 团队的核心信条是：**不要为今天的模型做产品，要为六个月后的模型做产品。** 在 Claude Code 最初发布的时候，模型只能写 Boris 大约 10-20% 的代码。产品并不好用。但他们赌的是模型会变强——而且他们知道它会变强，因为 Anthropic 的三位联合创始人就是 Scaling Laws 论文的前三位作者。指数增长不是一种信念，是他们的日常经验。",
        "",
        "在 Claude Code 团队的办公区墙上，挂着一份装裱好的 Rich Sutton 的《苦涩的教训》（The Bitter Lesson）——核心论点是：更通用的模型最终总是胜过更专门的模型。这就是为什么他们不给 Claude Code 加复杂的脚手架和工作流编排。Boris 说脚手架（scaffolding）或许能提升10-20%的性能，但下一个模型出来，这些增量就被抹平了。与其不断重建脚手架，不如把赌注押在模型本身。",
        "",
        "这种\"为未来的模型而建\"的哲学也解释了 Claude Code 的一个惊人事实：**Claude Code 没有任何一行代码是六个月前的。** 产品被反复重写——删掉不再需要的工具，加入新的工具，每隔几周迭代一次。代码的保质期可能只有几个月。",
        "",
        "而且 Claude Code 团队用 Claude Code 开发 Claude Code。Boris 说自从 Opus 4.5 以来，他个人 100% 的代码都由 Claude Code 编写，他已经卸载了 IDE，没有手动编辑过一行代码。他每天提交10到30个 PR。今年1月推出的 Cowork，由4名工程师在10天内完成，完全由 Claude Code 编写。甚至 Plan Mode 这个功能——Boris 说它实质上只是在提示词里加了一句\"请先不要写代码\"——是他在一个周日晚上看 GitHub Issues 时花30分钟写出来的，第二天早上就上线了。",
        "",
        "产品用自己来构建自己。用户的需求直接变成功能。这种自我强化的循环，竞争对手很难复制。",
        "",
        "Boris 认为 Plan Mode 的寿命有限。\"我觉得 Plan Mode 可能不会存在太久，\"他说，\"也许一个月。\"Claude Code 现在已经能够自己进入 Plan Mode——判断任务是否复杂到需要先规划再动手。下一步是模型完全不需要任何显式模式就能自行判断。这就是\"为未来的模型而建\"在实践中的样子——功能在溶解为模型的基础能力。",
        "",
        "还有一个更深层的原因，让这件事只能发生在 Anthropic。被问到今年会发生什么时，Boris 给了两个边界。下界：编码对所有人来说都被解决了，\"软件工程师\"这个头衔开始消失，取而代之的可能是\"builder\"或者\"产品经理\"。上界则\"恐怖得多\"——ASL4，模型开始递归式自我改进。Anthropic 的安全等级体系定义了在发布更强模型之前必须满足的严格标准。Boris 说你在 Anthropic 的食堂偷听到的对话，人们谈论的是 AI 安全——\"这真的是每个人最关心的事情\"。构建最强的编码 Agent 和构建最审慎的安全文化，在 Anthropic 不是矛盾的——它们是同一个使命。",
        "",
        "## 顶尖实践者的共识",
        "",
        "如果只是我一个人在说这些，可能是个人偏见。但现在说这些话的是软件行业最顶尖的实践者——定义了现代编程语言和开发框架的人。",
        "",
        "Andrej Karpathy——一年前造了\"氛围编码\"这个词的人——说：\"我已经明显感觉到，我手动编写代码的能力在慢慢退化。在大脑中，代码生成和代码解读是两种不同的能力。\"",
        "",
        "NodeJS 创始人 Ryan Dahl：\"人类编写代码的时代已经结束了。\"",
        "",
        "Ruby on Rails 创始人 DHH：\"手动写 Ruby 代码如今已成为一种奢侈体验，这门手艺或许很快会成为失传的艺术。\"",
        "",
        "Linux 之父 Linus Torvalds 也开始用 Claude Code。",
        "",
        "前 Google 工程师 Steve Yegge 写道：一个 Anthropic 工程师目前的生产力平均是 **Google 巅峰时期一个 Google 工程师的 1000 倍**。三年前，行业还在争论\"10 倍工程师\"是不是真的存在。现在我们在讨论的是 1000 倍——而且是以巅峰期的 Google 工程师为基准。如果不是数据佐证，这个数字听起来简直荒谬。",
        "",
        "在 Anthropic 内部，自 Claude Code 引入以来，**每个工程师的生产力提升了150%**。Boris 的前一份工作是在 Meta 负责全公司的代码质量——Facebook、Instagram、WhatsApp 的所有代码库。在那里，一个专门的团队花一整年的精力，能看到几个百分点的生产力提升。150% 的数字在传统软件工程的语境里是不可想象的。",
        "",
        "共识已经很清晰。定义了现代编程的实践者们在用各自的方式说同一件事：手写代码的时代正在结束。",
        "",
        "但如果你觉得这只是关于编程的故事，你低估了正在发生的事。编码只是滩头阵地——不是终点。[第八篇](/the-printing-press-moment-zh)会看看，当范式转移扩展到代码之外，会发生什么。",
        "",
        "---",
        "",
        "**有空的话，推荐看看：**",
        "",
        "- [SemiAnalysis: Claude Code is the Inflection Point](https://newsletter.semianalysis.com/p/claude-code-is-the-inflection-point)",
        "- [Inside Claude Code With Its Creator Boris Cherny (YC / Light Cone)](https://www.youtube.com/watch?v=PQU9o_5rHC4)"
    ],
    "claudecode-en": [
        "",
        "## A Report, a Number",
        "",
        "In early February, SemiAnalysis published a report: \"Claude Code is the Inflection Point.\"",
        "",
        "One number is worth singling out: as of February 2nd, Claude Code's daily code commits account for 4% of all GitHub public commits. At its current trajectory, that number will exceed 20% by the end of 2026.",
        "",
        "4% doesn't sound like much. But GitHub has tens of millions of active developers. This means a single product — a command-line tool launched just 13 months ago, not an IDE, not a SaaS platform, a terminal CLI — has already left a non-trivial mark on the world's codebase.",
        "",
        "And it's not just commits. Mercury's data shows 70% of startups now choose Claude as their primary model. NASA used Claude Code to plot the trajectory for the Perseverance Mars rover — the team printed posters of it because, as Boris put it, \"this is just the coolest thing.\" From YC startups to Mars missions, the footprint is wider than any single metric captures.",
        "",
        "As someone who works inside Claude Code every day, this number doesn't surprise me. What surprises me is that mainstream analysts are finally taking it seriously.",
        "",
        "## The Model Didn't Change — It Got a Harness",
        "",
        "SemiAnalysis used an analogy I think nails it: the ChatGPT era is Web 1.0, the Claude Code era is Web 2.0.",
        "",
        "Web 1.0 was static pages — you send a request, the server returns a page. TCP/IP was the underlying protocol, but the real trillion-dollar value came from the dynamic applications built on top of it: search engines, social networks, e-commerce platforms.",
        "",
        "The ChatGPT API is AI's TCP/IP. You send a text, the model returns a text. Call and response, back and forth. The model's capabilities are there, but it's being treated as a raw commodity.",
        "",
        "Claude Code does something fundamentally different. It wraps the model in a **harness** — reading the codebase, formulating execution plans, invoking tools, running commands, verifying results, self-debugging, iterating until the task is complete. The underlying model is the same, but the harness pulls the model's potential from \"answering questions\" to \"completing tasks.\"",
        "",
        "Boris Cherny — Claude Code's creator — told an origin story in recent interviews that perfectly illustrates this. In September 2024, he was just trying out Anthropic's API, so he wrote the simplest possible terminal chat program in TypeScript. Then he gave the model a Bash tool — purely because that's what the documentation example showed. The model could now read files and execute commands. He casually asked: \"What music am I listening to?\"",
        "",
        "The model wrote an AppleScript, took control of his Mac, queried the music player, and told him the name of the song playing. This was still Sonnet 3.5 — a model that looks quite limited by today's standards. Nobody taught it to do this. Nobody wrote \"please control the user's computer\" in the prompt. Once given the tool, **the model figured out on its own how to use it to complete the task**. Boris said it was the first time he truly felt AGI: \"This model just wants to use tools. That's all it wants to do.\"",
        "",
        "The harness doesn't force the model to do things — it makes possible what the model already wants to do.",
        "",
        "This is the core of the paradigm shift. Not that the model got smarter — but that **we finally learned how to harness it**.",
        "",
        "In the ChatGPT era, 90% of the model's capability was wasted. You ask a question, it gives an answer, then waits for your next question. Between each turn, all context, judgment, and intermediate state gets discarded. What Claude Code's harness does is: keep the model working continuously, maintain state across multiple steps, self-adjust when hitting obstacles, and keep converging on the goal. The model's intelligence didn't change, but utilization went from 10% to 90%.",
        "",
        "Most people — the 99.99% I discussed in [Part 5](/the-last-mile-of-ai) — still think of AI as \"a slightly smarter search engine.\" But Claude Code has already proven that AI can be an executor. You give it an objective, it gives you an outcome.",
        "",
        "## Why Anthropic",
        "",
        "This question is worth unpacking.",
        "",
        "It's not because Anthropic has the strongest model — on benchmarks, the gap between top models keeps narrowing. It's not because Anthropic has the most compute — OpenAI still leads there. It's not because Anthropic has the largest user base — ChatGPT's MAU dwarfs Claude's.",
        "",
        "Anthropic got one thing right: **it saw that orchestration matters more than generation.**",
        "",
        "While the rest of the industry was racing to squeeze two more percentage points on benchmarks, Anthropic was asking a different question: how do you make a model actually do things for people?",
        "",
        "The answer wasn't a better chat interface. It wasn't a prettier IDE plugin. It was a terminal tool — a seemingly \"primitive\" command-line interface.",
        "",
        "And this choice wasn't even deliberate. Boris said in interviews that he made Claude Code a terminal program purely because he was the only person on the team at the time — he didn't need or have time to build a UI. It was originally just a prototype, the cheapest possible starting point. But they stayed in the terminal for a surprising reason: the model was improving so fast that they felt any UI would be obsolete within six months. The terminal's \"primitiveness\" actually made it the most durable form factor.",
        "",
        "The adoption trajectory confirmed it. Two days after the first prototype, Boris's teammate Robert was already using it to code — without being asked. When Anthropic prepared to launch externally, CEO Dario Amodei looked at the internal usage chart and asked: \"The DAU chart is vertical. Are you forcing engineers to use it?\" Boris: \"No. I just posted about it and they've just been telling each other about it.\" The product sold itself.",
        "",
        "This choice is counterintuitive. IDE plugins feel friendlier, more \"product-like.\" But terminal means **full computer access**. An agent in the terminal isn't assisting you in a sandboxed code editor — it's operating autonomously across your entire computing environment. Reading the file system, running shell commands, calling APIs, deploying services. The action space is unlimited.",
        "",
        "The Cursor and Copilot paradigm: human writes code, AI assists.",
        "",
        "The Claude Code paradigm: **human describes intent, AI executes.**",
        "",
        "This isn't a feature gap. It's a fundamental paradigm gap.",
        "",
        "Another thing unique to Anthropic is its judgment about the model capability curve. Boris says Claude Code's team lives by a core belief: **don't build for today's model — build for the model six months from now.** When Claude Code first launched, the model could only write about 10-20% of Boris's code. The product wasn't great. But they were betting the model would improve — and they knew it would, because Anthropic's three co-founders are the first three authors of the Scaling Laws paper. Exponential growth isn't a belief for them; it's daily experience.",
        "",
        "On the wall of the Claude Code team's office hangs a framed copy of Rich Sutton's \"The Bitter Lesson\" — the core argument being that more general models always end up beating more specialized ones. This is why they don't add complex scaffolding and workflow orchestration to Claude Code. Boris says scaffolding might improve performance by 10-20%, but the next model wipes out those incremental gains. Rather than constantly rebuilding scaffolding, they bet on the model itself.",
        "",
        "This \"build for the future model\" philosophy also explains a startling fact about Claude Code: **not a single line of Claude Code's codebase is from six months ago.** The product gets rewritten constantly — removing tools that are no longer needed, adding new ones, iterating every few weeks. Code shelf-life might be just a few months.",
        "",
        "And the Claude Code team builds Claude Code with Claude Code. Boris says that since Opus 4.5, 100% of his personal code is written by Claude Code — he's uninstalled his IDE and hasn't manually edited a single line. He submits 10 to 30 PRs per day. Cowork, launched in January, was built by 4 engineers in 10 days, entirely written by Claude Code. Even Plan Mode — which Boris says is essentially just adding one sentence to the prompt saying \"please don't write code yet\" — was something he built in 30 minutes on a Sunday night while browsing GitHub Issues, and shipped the next morning.",
        "",
        "The product builds itself with itself. User needs become features directly. That self-reinforcing loop is very hard for competitors to replicate.",
        "",
        "Boris thinks Plan Mode's days are numbered. \"I think plan mode probably has a limited lifespan,\" he said. \"Maybe in a month.\" Claude Code can already enter plan mode on its own — detecting when a task is complex enough to warrant planning before coding. The next step is the model figuring it out without any explicit mode at all. This is what \"build for the model six months from now\" looks like in practice — features dissolving into baseline model capability.",
        "",
        "There's also a deeper reason it's Anthropic. When asked what's going to happen this year, Boris framed it in two bounds. The lower bound: coding gets solved for everyone, the title \"software engineer\" starts to disappear, replaced by \"builder\" or \"product manager.\" The upper bound is \"a lot scarier\" — ASL4, where models become recursively self-improving. Anthropic's safety levels define strict criteria that must be met before releasing more capable models. Boris says if you overhear lunchroom conversations at Anthropic, people are talking about AI safety — \"this is really the thing that everyone cares about more than anything.\" Building the most capable coding agent and building the most cautious safety culture aren't contradictions at Anthropic — they're the same mission.",
        "",
        "## The Practitioner Consensus",
        "",
        "If it were just me saying this, you could dismiss it as personal bias. But the people saying it now are the most accomplished practitioners in software — the ones who defined modern programming languages and development frameworks.",
        "",
        "Andrej Karpathy — the man who coined \"vibe coding\" a year ago — says: \"I've already noticed that I am slowly starting to atrophy my ability to write code manually. Generation and discrimination are different capabilities in the brain.\"",
        "",
        "Ryan Dahl, creator of NodeJS: \"The era of humans writing code is over.\"",
        "",
        "DHH, creator of Ruby on Rails: \"Writing Ruby code by hand in a text editor feels like such a luxury. Maybe this will soon be a lost art.\"",
        "",
        "Even Linus Torvalds is vibe coding with Claude Code.",
        "",
        "Steve Yegge — former Google engineer turned Anthropic advocate — wrote that an Anthropic engineer currently averages **1,000x more productivity than a Google engineer at Google's peak**. Three years ago, the industry was still debating whether \"10x engineers\" existed. Now the claim is 1,000x — on top of a Google engineer in their prime. The scale of this would be absurd if it weren't corroborated by the data.",
        "",
        "Internally at Anthropic, since Claude Code was introduced, **each engineer's productivity has increased by 150%**. Boris's previous job was leading company-wide code quality at Meta — covering the codebases of Facebook, Instagram, and WhatsApp. There, a dedicated team spending an entire year could see a few percentage points of productivity improvement. 150% in that context is unimaginable.",
        "",
        "The consensus is clear. The practitioners who defined modern programming are saying the same thing, each in their own way: the era of writing code by hand is ending.",
        "",
        "But if you think this is only about programming, you're underestimating what's happening. Coding is the first beachhead — not the destination. [Part 8](/the-printing-press-moment) looks at what happens when the paradigm shift spreads beyond code.",
        "",
        "---",
        "",
        "**References:**",
        "",
        "- [SemiAnalysis: Claude Code is the Inflection Point](https://newsletter.semianalysis.com/p/claude-code-is-the-inflection-point)",
        "- [Inside Claude Code With Its Creator Boris Cherny (YC / Light Cone)](https://www.youtube.com/watch?v=PQU9o_5rHC4)"
    ],
    "manager-zh": [
        "",
        "## \"帮我分析一下这个\"",
        "",
        "[第五篇](/the-last-mile-of-ai-zh)里，我讲了一个周末手把手教一个非工程师朋友用 Claude Code 的经历。基础设施的门槛很残酷，认知鸿沟更深。但第三个发现最反直觉。",
        "",
        "我朋友在学会基本操作之后，开始自己给 Claude Code 布置任务。他的指令是这样的：",
        "",
        "\"帮我分析一下这个。\"",
        "",
        "什么数据？分析什么维度？结论给谁看？用来做什么决策？格式要求？——全都没说。",
        "",
        "Claude Code 当然可以猜。它会给出一个合理的默认分析。但这就像你对一个极其能干的新员工说\"帮我弄一下那个东西\"——你可能会得到一个结果，但几乎肯定不是你想要的结果。",
        "",
        "**问题不在 AI 的能力——在人的管理能力。**",
        "",
        "我花了半天时间教他的不是怎么用 Claude Code 的功能——而是怎么下指令。怎么把一个模糊的需求拆解成清晰的 spec。怎么提供足够的上下文。怎么定义成功标准。怎么在 Agent 给出第一版之后，给出有针对性的反馈而不是\"不太对，再改改\"。",
        "",
        "这本质上是**管理培训**。",
        "",
        "举个具体例子。比较这两种指令：",
        "",
        "\"帮我写一个 Python 脚本解析这个 CSV\"——你在规定步骤。\"我有一份销售数据，我需要知道哪些客户在过去三个月里下单频率下降了，以及可能的原因\"——你在描述目标。让 Agent 决定怎么做，结果几乎总是比你预设路径要好。",
        "",
        "上下文同样重要。你是谁，这个结果给谁看，你要用它来做什么决定。同一份数据，给老板看的和给投资人看的完全不同。Agent 不是读心术——你给的背景越多，结果越准。",
        "",
        "我们一直在问\"AI 能为你做什么\"，但真正的问题是\"你能为 AI 做什么\"。你能不能提供清晰的需求？充分的上下文？如果你自己还没想清楚要什么，你能不能用 Agent 作为协作者来一起理清思路，而不是期待它读心术？",
        "",
        "反过来想：如果你是一个 CEO，你的直属下属是一个能力极强但完全没有背景信息的人——你会怎么管理他？你不会说\"帮我弄一下\"。你会给他看数据，解释背景，定义目标，约定交付标准。",
        "",
        "**对 AI 也一样。你才是 Manager。**",
        "",
        "Boris Cherny——Claude Code 的创造者——对此有一个让他自己都意外的观察。在 Anthropic 内部，更年轻、经验更少的工程师反而往往比资深工程师更会用 Claude Code。老工程师们根深蒂固的习惯和对\"正确做法\"的强烈主张，反而成了障碍。\"最重要的能力是科学思维和第一性原理思考，\"Boris 说，\"过去那些强烈的技术观点很多已经不适用了。\"",
        "",
        "这对非工程师学用 Agent 同样适用。我朋友缺乏工程背景，这不完全是障碍——某种程度上反而是优势。他没有关于软件\"应该怎么运作\"的先入之见。一旦学会了管理技能——如何框定清晰的目标、提供充分的上下文——他不需要\"忘掉\"任何旧习惯。初学者心态，在 Agent 时代反而比专家心态更适合。",
        "",
        "## 从工具到伙伴",
        "",
        "我朋友的心智模型在这个周末经历了三次跃迁。",
        "",
        "**第一天**：搜索引擎。他问 Claude Code 问题，像用百度一样。\"什么是 GCP？\"\"怎么注册？\"他在等答案。",
        "",
        "**第一天晚上**：工具。他开始让 Claude Code 做事。\"帮我写这个脚本。\"\"把这个文件格式转一下。\"他在使用工具。",
        "",
        "**第二天结束**：协作者。他开始和 Claude Code 讨论。\"我有一个想法，你觉得可行吗？\"\"这个方案有什么我没想到的风险？\"\"我们能不能换个思路？\"他不再是在使用工具——他在和一个伙伴合作。",
        "",
        "这三步跃迁——搜索引擎、工具、协作者——是整个市场需要经历的进化。",
        "",
        "绝大多数人还在第一步。他们把 AI 当成一个更聪明的搜索引擎，给它一个问题，期待一个答案。少数人到了第二步，把 AI 当工具使用——但仍然是单向的、指令式的。极少数人到了第三步，把 AI 当成真正的协作伙伴。",
        "",
        "这和我在[第一篇](/the-companion-vision-zh)里写的伴侣愿景是同一条线。一个真正理解你的 AI 伴侣，需要的不只是技术上的记忆编排和人格建模——**它需要一个愿意被理解的人。**",
        "",
        "如果你不愿意提供上下文，不愿意说出真实想法，不愿意花时间和 Agent 建立共识——那再好的记忆系统也帮不了你。AI 伴侣的效果上限，不取决于 AI 的能力，取决于你投入的深度。",
        "",
        "## 你对模型能力的判断永远滞后",
        "",
        "Boris 讲了一个让他自己也被迫重新校准认知的故事。有一次 Claude Code 出了内存泄漏，他按照老办法调试——取堆快照，在 DevTools 里分析，逐步排查。同时，团队里一个更年轻的工程师直接问 Claude Code：\"好像有内存泄漏，你能查一下吗？\" Claude Code 自己取了堆快照，写了一个临时分析工具来解析数据，找到了泄漏点，提交了修复 PR——**比 Boris 手动调试更快**。他说自己必须不断提醒自己：现在的模型不是三个月前的模型了。你脑子里对模型能力的判断永远滞后于现实。",
        "",
        "Boris 说他团队里最强的工程师呈现两种极端：一种是极致的专家，在某个领域理解得比任何人都深；另一种是超级通才，同时横跨产品、设计、用户研究和工程。工程师 Daisy 就是新范式思维的典型。她没有直接去实现一个功能，而是先让 Claude Code 造了一个\"能测试任意工具\"的工具——然后用这个元工具让 Claude 自己编写并验证了实际的功能代码。Boris 说：\"大多数人还没理解这种思维。\"关键技能不再是写代码，而是想清楚怎么让 Agent 去解决问题。",
        "",
        "**代码编写这个曾被视为核心技能的工作，正在变成 AI 的基础能力。** 程序员的竞争力正在从\"写代码\"转向\"管理 AI 写代码\"。",
        "",
        "我自己的体验也是这样。我不再\"写\"代码——我描述我要什么，Claude Code 来实现。我审代码，做决策，给反馈。角色从程序员变成了项目经理。",
        "",
        "## Agent 时代的三条原则",
        "",
        "对于已经跨过那道门槛的人，这是 Boris 的三条进阶原则：",
        "",
        "**校准你的信任。** 前面讲的内存泄漏故事有一个核心教训：**你对模型能力的判断永远滞后于现实。** 你觉得它做不到的事，试一下再说。最大的浪费不是给 Agent 太难的任务让它失败——而是你从来没给它机会去尝试你以为它做不到的事。",
        "",
        "**保持指令精简。** Boris 自己的 Claude.md——控制 Claude Code 行为方式的配置文件——只有两行。一行是自动合并 PR，另一行是把 PR 发到团队 Slack 频道。就这些。他的建议是：\"删掉你的 Claude.md，从头开始。很多人把这件事过度工程化了。用最少的指令让模型走上正轨就好。每次模型更新，你需要写的指令就更少。\"",
        "",
        "**用更多 Agent 解决更难的问题。** Boris 根据任务难度来调整并行 sub-agent 的数量。简单的 bug？一个 Agent。中等复杂度？三个 Agent 并行研究。特别难的？五个甚至十个 Agent，每个从不同角度同时调查。核心洞察：向一个问题投入更多独立的上下文窗口，本身就是一种算力——Boris 称之为\"不相关的上下文窗口\"（uncorrelated context windows）。更多 Agent 意味着更强的能力，而不仅仅是更快的速度。",
        "",
        "## 真正重要的问题",
        "",
        "甚至招聘方式都在变。YC 正在尝试让工程候选人提交 Claude Code 会话记录——他们和 Agent 一起开发功能的完整过程。\"你能看出一个人怎么思考，\"YC 的合伙人说，\"他们会不会看日志？Agent 跑偏了能不能纠正？会不会用 Plan Mode？有没有系统思维？\"Boris 想做一个蜘蛛网图——像 NBA 2K 里那种——从系统思维、测试意识、产品直觉、自动化能力等维度给工程师打分。",
        "",
        "Boris 自己的招聘方式也印证了这种转变。他不找技术观点最强的人，也不看最漂亮的简历。他问一个问题：\"说一个你错了的例子。\"他想看的是一个人能不能在事后认识到自己的错误，能不能承担责任，能不能从中学到东西。\"很多非常资深的人永远不会真正承认一个错误，\"他说，\"但我大概一半的时候是错的。你只能不断去试。\"",
        "",
        "问题不再是\"你会不会写代码\"，而是\"你能不能驾驭 Agent 去构建需要的东西\"。",
        "",
        "工具已经在了。能力已经在了。瓶颈在你——你的管理能力，你的投入深度，你用目标而非步骤来思考的能力。",
        "",
        "[第七篇](/why-claude-code-zh)退一步看更大的图景：为什么偏偏是 Claude Code 成了拐点，以及这一切意味着什么。"
    ],
    "manager-en": [
        "",
        "## \"Help Me Analyze This\"",
        "",
        "In [Part 5](/the-last-mile-of-ai), I described teaching a non-engineer friend to use Claude Code over a weekend. The infrastructure gap was brutal. The perception gap was even bigger. But the third discovery was the most counterintuitive.",
        "",
        "After my friend learned the basics, he started assigning tasks to Claude Code on his own. His instructions looked like this:",
        "",
        "\"Help me analyze this.\"",
        "",
        "What data? Along what dimensions? Who's the audience for the conclusions? What decisions will it inform? What format? — None of that specified.",
        "",
        "Claude Code can guess, of course. It'll produce a reasonable default analysis. But this is like telling an extremely capable new hire \"help me deal with that thing\" — you'll get a result, but it's almost certainly not the one you wanted.",
        "",
        "**The problem isn't AI capability — it's human management skill.**",
        "",
        "I spent half a day teaching him not how to use Claude Code's features — but how to give instructions. How to decompose a vague need into a clear spec. How to provide sufficient context. How to define success criteria. How to give targeted feedback after the first draft instead of \"not quite right, try again.\"",
        "",
        "This is essentially **management training.**",
        "",
        "Here's a concrete example. Compare these two instructions:",
        "",
        "\"Write me a Python script to parse this CSV\" — you're prescribing steps. \"I have sales data, I need to know which customers have decreased their order frequency in the past three months, and possible reasons why\" — you're describing a goal. Let the agent decide how to get there. The result is almost always better than your predetermined path.",
        "",
        "Context matters just as much. Who you are, who will see this output, what decision you'll make with it. The same data analysis looks completely different presented for your boss versus for an investor. The agent isn't a mind reader — the more background you give it, the more accurate the result.",
        "",
        "We keep asking \"what can AI do for you,\" but the real question is \"what can you do for AI.\" Can you provide clear requirements? Sufficient context? If you don't know what you want yet, can you use the agent as a collaborator to figure it out together, instead of expecting it to read your mind?",
        "",
        "Flip the perspective: if you're a CEO and your direct report is extremely capable but has zero background information — how would you manage them? You wouldn't say \"deal with that.\" You'd show them the data, explain the context, define the objectives, agree on delivery standards.",
        "",
        "**Same with AI. You are the manager.**",
        "",
        "Boris Cherny — Claude Code's creator — made an observation about this that surprised even him. At Anthropic, newer engineers — people with less experience and fewer strong opinions — often use Claude Code more effectively than veterans. The senior engineers' deeply ingrained habits and strong convictions about \"the right way to do things\" actually get in the way. \"The biggest skill is people that can think scientifically and from first principles,\" Boris said. \"A lot of these strong opinions just aren't relevant anymore.\"",
        "",
        "This applies directly to non-engineers learning to use agents. My friend's lack of engineering background wasn't just a barrier — in some ways, it was an advantage. He had no preconceptions about how software \"should\" work. Once he learned the management skill — how to frame clear goals and provide context — he had nothing to unlearn. The beginner's mind, it turns out, is better suited to the agent era than the expert's.",
        "",
        "## From Tool to Partner",
        "",
        "My friend's mental model went through three phase shifts over the weekend.",
        "",
        "**Day 1**: Search engine. He asked Claude Code questions like he was using Google. \"What is GCP?\" \"How do I register?\" He was waiting for answers.",
        "",
        "**Day 1 evening**: Tool. He started making Claude Code do things. \"Write this script for me.\" \"Convert this file format.\" He was operating a tool.",
        "",
        "**End of Day 2**: Collaborator. He started discussing with Claude Code. \"I have an idea — do you think it's feasible?\" \"What risks am I not seeing in this approach?\" \"Can we try a different angle?\" He wasn't using a tool anymore — he was working with a partner.",
        "",
        "These three phase shifts — search engine, tool, collaborator — are the evolution the entire market needs to undergo.",
        "",
        "The vast majority of people are still at step one. They treat AI as a smarter search engine: give it a question, expect an answer. A smaller group has reached step two, using AI as a tool — but still unidirectional, command-driven. Very few have reached step three, treating AI as a genuine collaborator.",
        "",
        "This connects directly to the companion vision I wrote about in [Part 1](/the-companion-vision). An AI companion that truly understands you requires more than memory orchestration and personality modeling on the technical side — **it requires a human willing to be understood.**",
        "",
        "If you won't provide context, won't share what you really think, won't invest time building shared understanding with the agent — then no memory system, however sophisticated, can help you. The upper bound of an AI companion's effectiveness isn't determined by AI capability. It's determined by the depth of your engagement.",
        "",
        "## Your Mental Model Is Always Lagging",
        "",
        "Boris told a story that forced even him to recalibrate his own assumptions. One time Claude Code had a memory leak, and he started debugging the old-fashioned way — taking heap snapshots, analyzing them in DevTools, tracing step by step. Meanwhile, a younger engineer on the team simply asked Claude Code: \"There seems to be a memory leak, can you look into it?\" Claude Code took its own heap snapshots, wrote a temporary analysis tool to parse the data, found the leak, and submitted a fix PR — **faster than Boris debugging manually**. He says he has to constantly remind himself: the model today isn't the model from three months ago. Your mental model of the model's capabilities is always lagging behind reality.",
        "",
        "The most effective engineers on Boris's team are bimodal: either extreme specialists who understand one domain deeper than anyone, or hyper-generalists who span product, design, user research, and engineering simultaneously. One engineer, Daisy, exemplified the new meta-thinking. Instead of implementing a feature directly, she first had Claude Code build a tool that could test arbitrary tools — then used that meta-tool to have Claude write and verify its own implementation. \"Not a lot of people get it yet,\" Boris said. The skill isn't coding anymore. It's thinking about how to set up the agent to solve the problem.",
        "",
        "**Code writing — once considered the core skill of software development — is becoming a baseline AI capability.** The programmer's competitive edge is shifting from \"writing code\" to \"managing AI that writes code.\"",
        "",
        "My own experience mirrors this exactly. I no longer \"write\" code — I describe what I want, and Claude Code implements it. I review code, make decisions, give feedback. My role shifted from programmer to project manager.",
        "",
        "## Three Principles for the Agent Era",
        "",
        "For those who've already crossed the threshold from tool-user to manager, here are three power-user principles from Boris:",
        "",
        "**Calibrate your trust.** The memory leak story has one core lesson: **your mental model of the model's capabilities is always lagging behind reality.** If you think it can't do something, try it anyway. The biggest waste isn't giving the agent a task too hard and watching it fail — it's never giving it the chance to attempt something you assumed it couldn't do.",
        "",
        "**Keep your instructions minimal.** Boris's personal Claude.md — the instruction file that shapes how Claude Code works for him — is just two lines. One enables auto-merge on pull requests. The other posts PRs to his team's Slack channel. That's it. His advice: \"Delete your Claude.md and start fresh. A lot of people overengineer this. Do the minimal possible thing to get the model on track. With every model, you have to add less and less.\"",
        "",
        "**Throw more agents at hard problems.** Boris calibrates the number of parallel sub-agents to a task's difficulty. Easy bug? One agent. Medium complexity? Three agents researching in parallel. Really hard? Five or even ten agents, each investigating a different angle simultaneously. The insight: throwing more independent context windows at a problem is itself a form of compute — what he calls \"uncorrelated context windows.\" More agents means more capability, not just more speed.",
        "",
        "## The Question That Matters",
        "",
        "Even hiring is changing. YC is experimenting with having engineering candidates submit Claude Code session transcripts — recordings of themselves building a feature with an agent. \"You can figure out how someone thinks,\" the YC partners explained. \"Do they look at the logs? Can they correct the agent when it goes off track? Do they use plan mode? Do they think about systems?\" Boris wants a spider chart — like in NBA 2K — rating engineers on dimensions like systems thinking, testing discipline, product sense, and automation instinct.",
        "",
        "Boris's own approach to hiring confirms the shift. He doesn't look for candidates with the strongest technical opinions or the most impressive resumes. He asks one question: \"What's an example of when you were wrong?\" He wants to see if people can recognize mistakes in hindsight, take ownership, and learn from them. \"A lot of very senior people will never really take the blame for a mistake,\" he said. \"But I'm wrong probably half the time. You just have to try stuff.\"",
        "",
        "The question is no longer \"can you write code?\" It's \"can you steer an agent to build what's needed?\"",
        "",
        "The tools are here. The capability is here. The bottleneck is you — your management skill, your willingness to engage, your ability to think in goals rather than steps.",
        "",
        "[Part 7](/why-claude-code) steps back to the bigger picture: why Claude Code specifically became the inflection point, and what it tells us about where this is all heading."
    ]
};
